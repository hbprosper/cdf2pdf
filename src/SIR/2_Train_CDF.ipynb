{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b5765d14-1f61-4931-b8cc-67b118ec6a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; import pandas as pd\n",
    "import scipy as sp; import scipy.stats as st\n",
    "import torch; import torch.nn as nn\n",
    "#use numba's just-in-time compiler to speed things up\n",
    "from numba import njit\n",
    "from sklearn.preprocessing import StandardScaler; from sklearn.model_selection import train_test_split\n",
    "import matplotlib as mp; import matplotlib.pyplot as plt; \n",
    "#reset matplotlib stle/parameters\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "#plt.style.use('seaborn-deep')\n",
    "mp.rcParams['agg.path.chunksize'] = 10000\n",
    "mp.rcParams['axes.linewidth'] = 1\n",
    "font_legend = 15; font_axes=15\n",
    "# %matplotlib inline\n",
    "from joblib import  Memory\n",
    "\n",
    "import copy; import sys; import os\n",
    "from IPython.display import Image, display\n",
    "from importlib import import_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a72a58bc-fa8a-4b74-86b2-e27dd1af1231",
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTSIZE=18\n",
    "font = {'family': 'serif', 'weight':'normal', 'size':FONTSIZE}\n",
    "mp.rc('font', **font)\n",
    "mp.rc('text',usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1588d740-dcae-4dd5-88a6-16e42865b096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a922b98d-3631-4c9c-a559-f0aff4a7fab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>I</th>\n",
       "      <th>li</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.556824</td>\n",
       "      <td>0.432547</td>\n",
       "      <td>[3.0000e+00,2.5413e+01,6.6242e+01,1.4076e+02,2...</td>\n",
       "      <td>[3.5465e-02,6.0205e-02,5.2629e-02,1.9994e-02,3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.917183</td>\n",
       "      <td>0.617733</td>\n",
       "      <td>[3.0000e+00,4.6435e+01,1.2668e+02,1.8865e+02,1...</td>\n",
       "      <td>[4.6994e-02,6.1737e-02,5.9416e-02,6.5321e-02,3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.222595</td>\n",
       "      <td>0.684092</td>\n",
       "      <td>[3.0000e+00,2.3207e+02,5.2139e+02,5.1127e+02,4...</td>\n",
       "      <td>[3.8465e-02,1.4980e-02,4.3391e-02,8.0108e-02,6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.513685</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>[3.0000e+00,6.2250e+00,8.8920e+00,1.2593e+01,1...</td>\n",
       "      <td>[1.2181e-01,1.2303e-01,6.9494e-02,8.3929e-02,6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.533168</td>\n",
       "      <td>0.343659</td>\n",
       "      <td>[3.0000e+00,1.3872e+01,2.8699e+01,5.5722e+01,9...</td>\n",
       "      <td>[2.9563e-02,5.4805e-02,2.3345e-02,1.7169e-01,5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.018504</td>\n",
       "      <td>0.236397</td>\n",
       "      <td>[3.0000e+00,1.7329e+01,4.0684e+01,9.1622e+01,1...</td>\n",
       "      <td>[3.5029e-02,7.6161e-02,9.8830e-02,2.7422e-02,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.183638</td>\n",
       "      <td>0.371210</td>\n",
       "      <td>[3.0000e+00,3.3838e+01,1.0217e+02,2.4462e+02,4...</td>\n",
       "      <td>[5.3251e-02,9.8350e-02,3.7443e-02,2.2209e-02,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.097239</td>\n",
       "      <td>0.421748</td>\n",
       "      <td>[3.0000e+00,5.7375e+01,2.0121e+02,4.4055e+02,5...</td>\n",
       "      <td>[2.2518e-02,4.6346e-02,2.5197e-02,5.0298e-02,4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.790416</td>\n",
       "      <td>0.309533</td>\n",
       "      <td>[3.0000e+00,6.4540e+00,9.3210e+00,1.3244e+01,1...</td>\n",
       "      <td>[6.6862e-02,4.2194e-02,5.7831e-02,3.8413e-02,3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.498675</td>\n",
       "      <td>0.419194</td>\n",
       "      <td>[3.0000e+00,2.5851e+01,6.8293e+01,1.4792e+02,2...</td>\n",
       "      <td>[2.1645e-02,1.3017e-02,1.2058e-01,4.5645e-02,5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        alpha      beta                                                  I  \\\n",
       "0    0.556824  0.432547  [3.0000e+00,2.5413e+01,6.6242e+01,1.4076e+02,2...   \n",
       "1    0.917183  0.617733  [3.0000e+00,4.6435e+01,1.2668e+02,1.8865e+02,1...   \n",
       "2    0.222595  0.684092  [3.0000e+00,2.3207e+02,5.2139e+02,5.1127e+02,4...   \n",
       "3    0.513685  0.231400  [3.0000e+00,6.2250e+00,8.8920e+00,1.2593e+01,1...   \n",
       "4    0.533168  0.343659  [3.0000e+00,1.3872e+01,2.8699e+01,5.5722e+01,9...   \n",
       "..        ...       ...                                                ...   \n",
       "245  0.018504  0.236397  [3.0000e+00,1.7329e+01,4.0684e+01,9.1622e+01,1...   \n",
       "246  0.183638  0.371210  [3.0000e+00,3.3838e+01,1.0217e+02,2.4462e+02,4...   \n",
       "247  0.097239  0.421748  [3.0000e+00,5.7375e+01,2.0121e+02,4.4055e+02,5...   \n",
       "248  0.790416  0.309533  [3.0000e+00,6.4540e+00,9.3210e+00,1.3244e+01,1...   \n",
       "249  0.498675  0.419194  [3.0000e+00,2.5851e+01,6.8293e+01,1.4792e+02,2...   \n",
       "\n",
       "                                                    li  \n",
       "0    [3.5465e-02,6.0205e-02,5.2629e-02,1.9994e-02,3...  \n",
       "1    [4.6994e-02,6.1737e-02,5.9416e-02,6.5321e-02,3...  \n",
       "2    [3.8465e-02,1.4980e-02,4.3391e-02,8.0108e-02,6...  \n",
       "3    [1.2181e-01,1.2303e-01,6.9494e-02,8.3929e-02,6...  \n",
       "4    [2.9563e-02,5.4805e-02,2.3345e-02,1.7169e-01,5...  \n",
       "..                                                 ...  \n",
       "245  [3.5029e-02,7.6161e-02,9.8830e-02,2.7422e-02,1...  \n",
       "246  [5.3251e-02,9.8350e-02,3.7443e-02,2.2209e-02,1...  \n",
       "247  [2.2518e-02,4.6346e-02,2.5197e-02,5.0298e-02,4...  \n",
       "248  [6.6862e-02,4.2194e-02,5.7831e-02,3.8413e-02,3...  \n",
       "249  [2.1645e-02,1.3017e-02,1.2058e-01,4.5645e-02,5...  \n",
       "\n",
       "[250 rows x 4 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIR_data = pd.read_csv('../../data/SIR_data.csv.gz')\n",
    "SIR_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "da0d4921-5b91-4b6a-b55e-95d57f4b4092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "4401\n"
     ]
    }
   ],
   "source": [
    "print(len(SIR_data.iloc[0]['I']))\n",
    "print(len(SIR_data.iloc[0]['li']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8a056eae-ef16-430d-bd53-3f9984c48bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdf(lst, x):\n",
    "\n",
    "    count = sum(1 for num in lst if num <= x)\n",
    "    return count / len(lst)\n",
    "\n",
    "\n",
    "def flatten_SIR_data(df):\n",
    "    \"\"\" and add cdf column\"\"\"\n",
    "    alpha_l = []\n",
    "    beta_l = []\n",
    "    Infected_l = []\n",
    "    li_l = []\n",
    "    true_CDF_l=[]\n",
    "    for rowind, row in df.iterrows():\n",
    "        li = eval(row['li'])\n",
    "        \n",
    "        for lambda_val in li:\n",
    "            true_CDF_l.append(cdf(li, lambda_val))\n",
    "    \n",
    "    for rowind, row in df.iterrows():\n",
    "    #     Infected = eval(row['I'])\n",
    "    #     Infected_l.append(Infected)\n",
    "        \n",
    "        li = eval(row['li'])\n",
    "        li_l.append(li)\n",
    "\n",
    "        \n",
    "        alpha_r = np.full_like(li, row['alpha'])\n",
    "        alpha_l.append(alpha_r)\n",
    "        \n",
    "        beta_r = np.full_like(li, row['beta'])\n",
    "        beta_l.append(beta_r)\n",
    "        \n",
    "        \n",
    "    \n",
    "    # for arr in [alpha_l, beta_l, Infected_l, li_l]:\n",
    "    #     arr = np.array(arr).flatten()\n",
    "    alpha_l = np.array(alpha_l).flatten()\n",
    "    beta_l = np.array(beta_l).flatten()\n",
    "    # Infected_l = np.array(Infected_l).flatten()\n",
    "    li_l = np.array(li_l).flatten()\n",
    "    true_CDF_l = np.array(true_CDF_l).flatten()\n",
    "    \n",
    "    data_flat = pd.DataFrame({\n",
    "        'alpha':alpha_l,\n",
    "        'beta': beta_l,\n",
    "        # 'I' :Infected_l,\n",
    "        'li':li_l,\n",
    "        'true_CDF':true_CDF_l \n",
    "    })\n",
    "    \n",
    "    return data_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c82f3f30-ec41-4d7d-867d-ed853c5180b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>li</th>\n",
       "      <th>true_CDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.556824</td>\n",
       "      <td>0.432547</td>\n",
       "      <td>0.035465</td>\n",
       "      <td>0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.556824</td>\n",
       "      <td>0.432547</td>\n",
       "      <td>0.060205</td>\n",
       "      <td>0.6125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.556824</td>\n",
       "      <td>0.432547</td>\n",
       "      <td>0.052629</td>\n",
       "      <td>0.5350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.556824</td>\n",
       "      <td>0.432547</td>\n",
       "      <td>0.019994</td>\n",
       "      <td>0.0725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.556824</td>\n",
       "      <td>0.432547</td>\n",
       "      <td>0.035213</td>\n",
       "      <td>0.3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0.498675</td>\n",
       "      <td>0.419194</td>\n",
       "      <td>0.077266</td>\n",
       "      <td>0.7225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0.498675</td>\n",
       "      <td>0.419194</td>\n",
       "      <td>0.043796</td>\n",
       "      <td>0.4475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0.498675</td>\n",
       "      <td>0.419194</td>\n",
       "      <td>0.014526</td>\n",
       "      <td>0.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0.498675</td>\n",
       "      <td>0.419194</td>\n",
       "      <td>0.055118</td>\n",
       "      <td>0.5675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0.498675</td>\n",
       "      <td>0.419194</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.5650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          alpha      beta        li  true_CDF\n",
       "0      0.556824  0.432547  0.035465    0.3400\n",
       "1      0.556824  0.432547  0.060205    0.6125\n",
       "2      0.556824  0.432547  0.052629    0.5350\n",
       "3      0.556824  0.432547  0.019994    0.0725\n",
       "4      0.556824  0.432547  0.035213    0.3300\n",
       "...         ...       ...       ...       ...\n",
       "99995  0.498675  0.419194  0.077266    0.7225\n",
       "99996  0.498675  0.419194  0.043796    0.4475\n",
       "99997  0.498675  0.419194  0.014526    0.0250\n",
       "99998  0.498675  0.419194  0.055118    0.5675\n",
       "99999  0.498675  0.419194  0.054795    0.5650\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIR_data_flat = flatten_SIR_data(SIR_data)\n",
    "SIR_data_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6bba98db-66b5-4d66-9456-ea6195934aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_t_x(df, target, source):\n",
    "    # change from pandas dataframe format to a numpy \n",
    "    # array of the specified types\n",
    "    t = np.array(df[target])\n",
    "    x = np.array(df[source])\n",
    "    return t, x\n",
    "\n",
    "def getwholedata_delta_SIR():\n",
    "    \"\"\" Get train test split arrays\"\"\"\n",
    "    \n",
    "    data = SIR_data_flat\n",
    "        \n",
    "    train_data, test_data = train_test_split(data, test_size=0.1)\n",
    "    #split the train data (0.8 of whole set) again into 0.8*0.8=0.64 of whole set\n",
    "    \n",
    "\n",
    "    train_data = train_data.reset_index(drop=True)\n",
    "    test_data  = test_data.reset_index(drop=True)\n",
    "\n",
    "    target='true_CDF'\n",
    "    # target='y'\n",
    "    # source = ['theta','nu','theta_hat','N','M']\n",
    "\n",
    "    # source = ['theta', 'nu', 'lambda', 'true_CDF']\n",
    "    source = ['alpha', 'beta', 'li']\n",
    "\n",
    "    train_t, train_x = split_t_x(train_data, target=target, source=source)\n",
    "    test_t,  test_x  = split_t_x(test_data,  target=target, source=source)\n",
    "    print('train_t shape = ', train_t.shape, '\\n')\n",
    "    print('train_x shape = ', train_x.shape, '\\n')\n",
    "    \n",
    "    # if valid:\n",
    "        #if you want to also make a validation data set\n",
    "    train_data, valid_data = train_test_split(train_data, test_size=0.015)\n",
    "    valid_data = valid_data.reset_index(drop=True)\n",
    "    valid_t, valid_x = split_t_x(valid_data, target=target, source=source)\n",
    "\n",
    "        \n",
    "    return train_t, train_x, test_t,  test_x, valid_t, valid_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dc1ee907-769d-418e-a360-0c23d8c43ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_t shape =  (90000,) \n",
      "\n",
      "train_x shape =  (90000, 3) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_t, train_x, test_t,  test_x, valid_t, valid_x = getwholedata_delta_SIR()\n",
    "N_Features = train_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "01d09696-6e36-4c50-befd-1f762a38c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_training_batch(x, t, batch_size):\n",
    "    # the numpy function choice(length, number)\n",
    "    # selects at random \"batch_size\" integers from \n",
    "    # the range [0, length-1] corresponding to the\n",
    "    # row indices.\n",
    "    rows    = np.random.choice(len(x), batch_size)\n",
    "    batch_x = x[rows]\n",
    "    batch_t = t[rows]\n",
    "    # batch_x.T[-1] = np.random.uniform(0, 1, batch_size)\n",
    "    return (batch_x, batch_t)\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class SinActivation(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SinActivation, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.sin(x)\n",
    "    \n",
    "    \n",
    "class SIR_Model(nn.Module):\n",
    "    #inherit from the super class\n",
    "    def __init__(self, nfeatures, ntargets, nlayers, hidden_size, dropout):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(nlayers):\n",
    "            if len(layers) ==0:\n",
    "                #inital layer has to have size of input features as its input layer\n",
    "                #its output layer can have any size but it must match the size of the input layer of the next linear layer\n",
    "                #here we choose its output layer as the hidden size (fully connected)\n",
    "                layer = nn.Linear(nfeatures, hidden_size)\n",
    "                # torch.nn.init.xavier_uniform_(layer.weight, gain=60)\n",
    "                torch.nn.init.xavier_normal_(layer.weight, \n",
    "                                             # gain=60\n",
    "                                            )\n",
    "                layers.append(layer)\n",
    "                #batch normalization\n",
    "                layers.append(nn.BatchNorm1d(hidden_size))\n",
    "                #Dropout seems to worsen model performance\n",
    "                # layers.append(nn.Dropout(dropout))\n",
    "                #ReLU activation \n",
    "                layers.append(nn.SiLU())\n",
    "                # layers.append(SinActivation())\n",
    "                # layers.append(GroupSort(num_groups=1))\n",
    "            else:\n",
    "                #if this is not the first layer (we dont have layers)\n",
    "                layer = nn.Linear(hidden_size, hidden_size)\n",
    "                # torch.nn.init.xavier_uniform_(layer.weight, gain=60)\n",
    "                torch.nn.init.xavier_normal_(layer.weight, \n",
    "                                             # gain=60\n",
    "                                            )\n",
    "                layers.append(layer)\n",
    "                # layers.append(nn.BatchNorm1d(hidden_size))\n",
    "                #Dropout seems to worsen model performance\n",
    "                # layers.append(nn.Dropout(dropout))\n",
    "                layers.append(nn.SiLU())\n",
    "                # layers.append(nn.Tanh())\n",
    "                # layers.append(nn.ReLU())\n",
    "                # layers.append(SinActivation())\n",
    "                \n",
    "                #output layer:\n",
    "        output_layer = nn.Linear(hidden_size, ntargets)\n",
    "        torch.nn.init.xavier_uniform_(output_layer.weight)\n",
    "        layers.append(output_layer) \n",
    "\n",
    "        # ONLY IF ITS A CLASSIFICATION, ADD SIGMOID\n",
    "        layers.append(nn.Sigmoid())\n",
    "            #we have defined sequential model using the layers in oulist \n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1a64c929-d34f-4fbe-bce7-c5e0bf74ea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMS(v):\n",
    "    return (torch.mean(v**2)) ** 0.5\n",
    "\n",
    "def average_quadratic_loss(f, t, x):\n",
    "    # f and t must be of the same shape\n",
    "\n",
    "    # inv = torch.where(t !=0, 1/torch.abs(t), 1)\n",
    "    \n",
    "    # inv_RMS = torch.where(t !=0, 1/RMS(t), 1)\n",
    "    \n",
    "    return  torch.mean(  (f - t)**2)\n",
    "\n",
    "def huber_loss(f, t, x):\n",
    "    delta= torch.Tensor([0.1])\n",
    "    error = f - t\n",
    "    abs_error = torch.abs(error)\n",
    "    quadratic = torch.minimum(abs_error, delta)\n",
    "    linear = (abs_error - quadratic)\n",
    "    return torch.mean(0.5 * quadratic ** 2 + delta * linear)\n",
    "\n",
    "def kl_divergence_loss(q, p, x):\n",
    "    criterion = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "    loss = criterion(torch.log(p), q)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def validate(model, avloss, inputs, targets):\n",
    "    # make sure we set evaluation mode so that any training specific\n",
    "    # operations are disabled.\n",
    "    model.eval() # evaluation mode\n",
    "    \n",
    "    with torch.no_grad(): # no need to compute gradients wrt. x and t\n",
    "        x = torch.from_numpy(inputs).float().to(device)\n",
    "        t = torch.from_numpy(targets).float().to(device)\n",
    "        # remember to reshape!\n",
    "        o = model(x).reshape(t.shape)\n",
    "    return avloss(o, t, x)\n",
    "def train_delta_r(model, optimizer, avloss,\n",
    "          batch_size, \n",
    "          n_iterations, traces, \n",
    "          step, window):\n",
    "    \n",
    "    # to keep track of average losses\n",
    "    xx, yy_t, yy_v, yy_v_avg = traces\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "\n",
    "    train_t, train_x, test_t,  test_x, _, _ = getwholedata_delta_SIR()\n",
    "\n",
    "        \n",
    "    n = len(test_x)\n",
    "    print('Iteration vs average loss')\n",
    "    print(\"%10s\\t%10s\\t%10s\" % \\\n",
    "          ('iteration', 'train-set', 'valid-set'))\n",
    "    \n",
    "    # training_set_features, training_set_targets, evaluation_set_features, evaluation_set_targets = get_data_sets(simulate_data=False, batchsize=batch_size)\n",
    "    \n",
    "    for ii in range(n_iterations):\n",
    "\n",
    "        # set mode to training so that training specific \n",
    "        # operations such as dropout are enabled.\n",
    "\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        # get a random sample (a batch) of data (as numpy arrays)\n",
    "        \n",
    "        #Harrison-like Loader\n",
    "        batch_x, batch_t = get_features_training_batch(train_x, train_t, batch_size)\n",
    "        \n",
    "        #Or Ali's Loader\n",
    "        # batch_x, batch_t = next(training_set_features()), next(training_set_targets())\n",
    "        # batch_x_eval, batch_t_eval = next(evaluation_set_features()), next(evaluation_set_targets())\n",
    "\n",
    "        with torch.no_grad(): # no need to compute gradients \n",
    "            # wrt. x and t\n",
    "            x = torch.from_numpy(batch_x).float().to(device)\n",
    "            t = torch.from_numpy(batch_t).float().to(device)    \n",
    "\n",
    "\n",
    "        outputs = model(x).reshape(t.shape)\n",
    "   \n",
    "        # compute a noisy approximation to the average loss\n",
    "        empirical_risk = avloss(outputs, t, x)\n",
    "        \n",
    "        # use automatic differentiation to compute a \n",
    "        # noisy approximation of the local gradient\n",
    "        optimizer.zero_grad()       # clear previous gradients\n",
    "        empirical_risk.backward()   # compute gradients\n",
    "        \n",
    "        # finally, advance one step in the direction of steepest \n",
    "        # descent, using the noisy local gradient. \n",
    "        optimizer.step()            # move one step\n",
    "        \n",
    "        if ii % step == 0:\n",
    "            \n",
    "            \n",
    "            #using Harrison-like loader\n",
    "            acc_t = validate(model, avloss, train_x[:n], train_t[:n]) \n",
    "            acc_v = validate(model, avloss, test_x[:n], test_t[:n])\n",
    "            \n",
    "            #using Ali's loader\n",
    "            # acc_t = validate(model, avloss, batch_x, batch_t) \n",
    "            # acc_v = validate(model, avloss, batch_x_eval, batch_t_eval)\n",
    "            \n",
    "\n",
    "            yy_t.append(acc_t)\n",
    "            yy_v.append(acc_v)\n",
    "            \n",
    "            # compute running average for validation data\n",
    "            len_yy_v = len(yy_v)\n",
    "            if   len_yy_v < window:\n",
    "                yy_v_avg.append( yy_v[-1] )\n",
    "            elif len_yy_v == window:\n",
    "                yy_v_avg.append( sum(yy_v) / window )\n",
    "            else:\n",
    "                acc_v_avg  = yy_v_avg[-1] * window\n",
    "                acc_v_avg += yy_v[-1] - yy_v[-window-1]\n",
    "                yy_v_avg.append(acc_v_avg / window)\n",
    "                        \n",
    "            if len(xx) < 1:\n",
    "                xx.append(0)\n",
    "                print(\"%10d\\t%10.6f\\t%10.6f\" % \\\n",
    "                      (xx[-1], yy_t[-1], yy_v[-1]))\n",
    "            else:\n",
    "                xx.append(xx[-1] + step)\n",
    "                    \n",
    "                print(\"\\r%10d\\t%10.6f\\t%10.6f\\t%10.6f\" % \\\n",
    "                          (xx[-1], yy_t[-1], yy_v[-1], yy_v_avg[-1]), \n",
    "                      end='')\n",
    "            \n",
    "    print()      \n",
    "    return (xx, yy_t, yy_v, yy_v_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2e961a50-fa75-462c-80fa-2a21b6775bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_untrained_SIR_model(PARAMS):\n",
    "    \"\"\"Load an untrained model (with weights initiatted) according to model paramateters in the \n",
    "    PARAMS dictionary\n",
    "\n",
    "    Args:\n",
    "        PARAMS (dict): dictionary of model/training parameters: i.e. hyperparameters and training parameters.\n",
    "\n",
    "    Returns:\n",
    "        utils.RegularizedRegressionModel object\n",
    "    \"\"\"\n",
    "    model = SIR_Model(\n",
    "        nfeatures=PARAMS['NFEATURES'],\n",
    "        ntargets=1,\n",
    "        nlayers=PARAMS[\"n_layers\"],\n",
    "        hidden_size=PARAMS[\"hidden_size\"],\n",
    "        dropout=PARAMS[\"dropout\"],\n",
    "        # activation=PARAMS[\"activation\"]\n",
    "    )\n",
    "    # model.apply(initialize_weights)\n",
    "    print('INITIATED UNTRAINED MODEL:',\n",
    "          # model\n",
    "         )\n",
    "    # print(model)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c1039cc3-0b3f-4f29-aa47-a47515f17b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIR_Model_PARAMS = {\n",
    "\"n_layers\": int(6),\n",
    "\"hidden_size\": int(12),\n",
    "\"dropout\": float(0.13),\n",
    "\"NFEATURES\":int(N_Features),\n",
    "\"activation\": \"SiLU\",\n",
    "'optimizer_name':'NAdam',\n",
    "    # 'optimizer_name':'RMSprop',\n",
    "'starting_learning_rate':float(0.00003),\n",
    "'momentum':float(0.9),\n",
    "'batch_size':int(60),\n",
    "'n_iterations': int(1e6),\n",
    "'traces_step':int(100),\n",
    "'L2':float(0.1),\n",
    "'MLE':False,\n",
    "'with_lambda_D':True,\n",
    "'pth_string':'Delta_r_nonMLE_SILU.pth'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cc5c18df-9d34-4cc8-815f-689fef8cdc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIATED UNTRAINED MODEL:\n",
      "train_t shape =  (90000,) \n",
      "\n",
      "train_x shape =  (90000, 3) \n",
      "\n",
      "Iteration vs average loss\n",
      " iteration\t train-set\t valid-set\n",
      "         0\t  0.085112\t  0.083895\n",
      "     58000\t  0.001319\t  0.001260\t  0.001260"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [118], line 12\u001b[0m\n\u001b[1;32m      6\u001b[0m optimizer_name\u001b[38;5;241m=\u001b[39mSIR_Model_PARAMS[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      9\u001b[0m optimizer_SIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39moptim, \u001b[38;5;28mstr\u001b[39m(optimizer_name))(untrained_SIR_model\u001b[38;5;241m.\u001b[39mparameters(), \n\u001b[1;32m     10\u001b[0m                                                            lr\u001b[38;5;241m=\u001b[39mSIR_Model_PARAMS[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarting_learning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 12\u001b[0m traces_SIR \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_delta_r\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muntrained_SIR_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m              \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_SIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m              \u001b[49m\u001b[43mavloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_quadratic_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;66;43;03m# avloss=huber_loss,\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m              \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCHSIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m              \u001b[49m\u001b[43mn_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSIR_Model_PARAMS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_iterations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtraces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraces_SIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m              \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraces_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m              \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [115], line 90\u001b[0m, in \u001b[0;36mtrain_delta_r\u001b[0;34m(model, optimizer, avloss, batch_size, n_iterations, traces, step, window)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# use automatic differentiation to compute a \u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# noisy approximation of the local gradient\u001b[39;00m\n\u001b[1;32m     89\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()       \u001b[38;5;66;03m# clear previous gradients\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m \u001b[43mempirical_risk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# compute gradients\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# finally, advance one step in the direction of steepest \u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# descent, using the noisy local gradient. \u001b[39;00m\n\u001b[1;32m     94\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()            \u001b[38;5;66;03m# move one step\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_torch/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_torch/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "untrained_SIR_model = load_untrained_SIR_model(SIR_Model_PARAMS)\n",
    "\n",
    "BATCHSIZE=SIR_Model_PARAMS[\"batch_size\"]\n",
    "traces_SIR = ([], [], [], [])\n",
    "traces_step = 2000\n",
    "optimizer_name=SIR_Model_PARAMS[\"optimizer_name\"]\n",
    "\n",
    "\n",
    "optimizer_SIR = getattr(torch.optim, str(optimizer_name))(untrained_SIR_model.parameters(), \n",
    "                                                           lr=SIR_Model_PARAMS[\"starting_learning_rate\"])\n",
    "\n",
    "traces_SIR = train_delta_r(model=untrained_SIR_model, \n",
    "              optimizer=optimizer_SIR, \n",
    "              avloss=average_quadratic_loss,\n",
    "                            # avloss=huber_loss,\n",
    "              batch_size=BATCHSIZE, \n",
    "              n_iterations=SIR_Model_PARAMS[\"n_iterations\"], \n",
    "              traces=traces_SIR, \n",
    "              step=traces_step, \n",
    "              window=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "25dbf923-938a-4f29-8ca0-62856a55f591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genutil import generate, observe, Fsolve, SIRdata\n",
    "\n",
    "def test_statistic(i, I):\n",
    "    a = [(d-f)**2/f for d, f in zip(i, I)]\n",
    "    return np.sqrt(np.array(a).mean()) / SIRdata.scale\n",
    "\n",
    "def generate_eval_data(alpha,beta, K=500):\n",
    "\n",
    "    apply_filter = True\n",
    "\n",
    "    # solve ODEs for current parameter point\n",
    "    soln = Fsolve(alpha, beta, SIRdata)\n",
    "    I    = soln.y[1]\n",
    "\n",
    "    # reduce number of significant figures\n",
    "    I = [float(int(1000*x))/1000 for x in I]\n",
    "    print(I)\n",
    "\n",
    "    # simulate K epidemics and compute the\n",
    "    # associated test statistics\n",
    "    params = (alpha, beta)\n",
    "    l = []\n",
    "    counts = []\n",
    "    for k in range(K):\n",
    "\n",
    "        # generate data for one epidemic (defined as a sequence of 4-tuples: [t, s, i, r])\n",
    "        # t: time of event\n",
    "        # s: number of suceptible individuals at time t\n",
    "        # i: number of affected individuals at time t\n",
    "        # r: number of removed individuals at time t\n",
    "        states = generate(params, SIRdata)\n",
    "\n",
    "        # observe epidemics at specified observations times T\n",
    "        obs = observe(SIRdata.T, states)\n",
    "        i = [x for s,x,r in obs] # get infected counts\n",
    "\n",
    "        if apply_filter:\n",
    "            try:\n",
    "                if i.index(0) < 3:\n",
    "                    continue\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        l.append( test_statistic(i, I) )\n",
    "        \n",
    "    true_CDF_l=[]    \n",
    "    for lambda_val in l:\n",
    "        true_CDF_l.append(cdf(l, lambda_val))\n",
    "    l = np.array(l)\n",
    "    alpha_l = np.full_like(l,alpha)\n",
    "    beta_l = np.full_like(l,beta)\n",
    "    \n",
    "    eval_df = pd.DataFrame({'alpha':alpha_l,\n",
    "                            'beta':beta_l,\n",
    "                            'li': l,\n",
    "                            'true_CDF': true_CDF_l\n",
    "                           })\n",
    "    eval_df = eval_df.sort_values(by='li')\n",
    "    \n",
    "    eval_array = eval_df[['alpha','beta','li']].to_numpy()\n",
    "    return eval_df, eval_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a4caf0d4-90ec-4179-90cc-7c1a45538646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 18.417, 42.551, 87.388, 144.975, 182.78, 179.684, 148.03, 109.612, 76.744, 51.876, 34.336, 22.42]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkcAAAHBCAYAAABjQh+vAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABe2UlEQVR4nO3deXgb1bk/8K8l76u8ZN9HCRB2ZCfspCVSoYWWlmvFbaHLr63tbrS9bbHqbhR6703lbpfuctrbjdI6UoEWuoAUaICyxVYSAiQsUvbdlsf7rvn9MdZYimVbtiWNlu/nefz4zJnRzOuxHL0558w5GZIkSSAiIiIiAIBG7QCIiIiIEgmTIyIiIqIgTI6IiIiIgjA5IiIiIgrC5IiIiIgoCJMjIiIioiBMjoiIiIiCMDkiIiIiCpKpdgDJpr29HY8//jhWr16NvLw8tcMhIiKiCAwMDODQoUO46aabUFFRMe2xTI5m6fHHH8edd96pdhhEREQ0Bw888ADuuOOOaY9hcjRLq1evBiDf3PXr16sbDBEREUVk//79uPPOO5XP8ekwOZqlQFfa+vXrYTAYVI6GiIiIZiOSITEckE1EREQUhMkRERERURAmR0RERERBmBwRERERBWFyRERERBQk4Z9WE0URFosFOp0OVqt1TudwuVxwOp3Q6/UQRREA0NDQEMUoiYiIKFUkbHJksVjg9XqxYcMGuFwuGI3GOZ3H4XCgpaUFdrtdqXO5XDCZTHA6ndEKl4iIiFJEwnarWa1W2O12NDQ0QKfTzekcoiiitrYW27ZtC6k3Go3w+Xxobm6OQqRERESUShI2OYqG7du3QxCEsMlVTU0NbDZb/IMiIiKihJbSyZHdbkdZWVnYfYIgwO12K2OQiIiIiIAUT45aW1shCELYfYF6r9cbz5CIiIgowaV0ciSK4ozjlZgcERERUbCEfVot1gJJk8/nUzcQIqJokyTAPwZIY+d894du+0fHy/4wx47XK8eMhTnWL39BmihL0vhXuPopjoU0EbdcCNoOsy/scdPtk0Kqon/+mfbF42c7d1+04g/zs0z8UJNrJAmjfgljga8xP8ZC6vwT+yZt+zHmB8b8EoZzSnHdFx8Mc834SNvkKFJDQ0MYGhpStnt7e1WMhogSmiQBo4PAcB8w3AsM9Y6Xe8a/9wEjA8DYsHzc6ND496DtsaHJ+8aGgLFRwD8iv3ZsVP7uHxmvPyeBkfxq3wlKUxkAssa/5uPU0IIoRDN3aZscBQZiTzVgO2Dr1q2499574xARESWMkQGgrx3obwf6OoC+s+PldmDABwyIwGAXMNQjJ0HDfeOJUK+cnBDRvEhhWqXiKW2To0g1Njbii1/8orK9Z88ebNq0ScWIiGheRoeB7mOAeGTyV/dxORka6VM7ylAZWkCbBWiy5O/BZU3m+JcWyNCMf9dOURf8XRN0jHb6Y6d8vRZAhlzO0AAZQWVkjG+fW3fOsYHjkDH+s2ac87OH25cRWo5oX5jjJu1DZK8LKstdRsCYFOgaysCo348xCRgdkzDmB0bG9w2O+HFMHMCxzgEc9Q3gaOcAOvtHAADS+HUkZGCicys0Vumc46arC3399OcPdy7lmtLk45S7lAHkZmmRm5WJvCwN8rK1yMvSIjc7E7lZGuRlaZGXPb4/W4vcLC3yMjXIy5a387K1yM3MRF72+LE5WcjL1CA3W4vFWeqmJymdHAmCMOWA68BYo6meZgvIyclBTk6Osl1YWBi9AIkoNkaHgY63gDOvAWcPAJ2Hga6j4wnQCYQbKzE3GUB2IZBTCGQXyOVptwuArHxAmw1k5o5/5QR9jW9rz9nWaKMUb+LpHRrF8Kgfo2N+jPgl+fuYhFG/H6NjEkbG/Bj1j38f3x4Zk48L3h/8Onn/+LHj5wk+/+iYFHIt+RxB5/VL55T942W/HKt//Px+f/ihONPKBFA0/jV/2VoNsjM1yBn/kstapS572nptyGvD18vl7EwN8seTn/xsLfLHE6CMc5PZFJHSyZHBYJhyHqNA0mQwGOIYERFF3XAfcGI3cGwXcGofcGY/0P6mPB5ntvJKgYIFQH4FUDD+FSjnl4/vKwfydEBuiZz4pOiHQ6x19A7hc3/ajX+/1aF2KKopL8iGfmEh1i4sxNoFhSgryJ5dgqPVQKPh+y8WUjo5MplMUy5W6/F45rxeGxGpqPsk4P0XcOwlOSE6/Vrk43wKFgC6lUDJCvm7biWgWzVet1xu4aGYGxwZwx2/fBEHTvWoHUpYGRlAllaDLE0GMrUaZGkzkKnRIFObgSytBpkh9XI5Wyvvz9SM1yuvnyjnZmmxqrxAToYWyskQJaaUSI5EUURra+ukZGfLli3KArbndp85HI4pEyciSiDD/cDh5wDPk/LX2f3TH6/JAirOAxauBxZdCCxYD5Tr5YQoOz8+MdMkkiThZNcgDpzqRtM/X1cSo9L8LFyxshSZmvHEIyTBCJdsyMdkT0pSQpOXc88V2J5qf2ZQvZatMWkvKZIjURSnnY/IbDbD5XLBZrOhrq5OqdfpdNi2bRssFgvsdrtS73A4IAgCqqurYxo3Ec3RyCDwxj+AvX+SE6Kx4fDHZWiAhRcByyuB5RuApQagYp08UJlUd7C9Dw+8cBivnujCgVM9EPsnd3V+6z0X4bbLl6kQHdHUEjY5ampqwq5du+D1epUvk8kEnU6HmpqakMTGZDKhtbUVVVVVk85TXV0NnU4Hi8UCvV6vjEFyOp3x+lGIKBKSJHeT7XkQePUh+VH5c2VogGWVgP5GYPV1cjLErrCE4vdLONU9iP0nu/GFlj3oGRyd8tgLFhfhposWxzE6oshkSNLsx9qnM7fbjcrKSrS1tXEwN1E0iEeAvS3A3j8CPs/k/cXLgHUmOSFac4M8aJpU1T88ihPiAI74+nG4Q/6Sy3042jmA4dHJk1AuKs7BBYuLsX5JMdYvKcKFS4ohLChkFxbFzWw+vxO25YiIUtjoEPDKQ8CePwCHnpm8P6sAuPA9wGUfAFZfD2hSehnIhCJJEnx9wzguDuDE+Jw8gfJxcQDHg+bmicRlK3T45YersKAoZ+aDiRIEkyMiip+hHqD118ALPwN6Tp6zMwNYc72cEK1/D7vL4uytM73400tH8PDu4+jom2KM1wxyMjVYWZaPVeX5WFlWgPMXF+K2y5chNyt152mi1MTkiIhib2QA2PVL4NkfAv3nzGtTpgcu/wBw6fsB3Qp14ksxfr+E3uFRdPWPoGtg4ks8Z7trYBhdAyPo6B2O6LF6TQawuDgXy0rzsFSXhxWl+VhZno9VZflYVV6AhUU5nHeHUgKTIyKKnbERwP074OnvntNSlAFccAtwzV3Aiis5keIs9AyOwHu2D972XnjO9OGIrx+d/cPoHhiBOJ70dA+MwD/H0aTZWg2uFMqwvDQfy0vzsEwnJ0LLSvOwqCgHmVp2cVLqY3JERLFxYg/w18/Ks1YrMoBLqoEbGoAF56kVWdIYGh3DI7uPY8/RLnjP9sLb3oezPUNRv45Wk4G1CwphrlqO/zAsRyknJ6Q0x+SIiKJrZADYaQX+/aPQmasvuBV4+1eBRRepF1sSOdM9iE8+0Ab3ETGi4zMygOLcLJTkyV+6/CwU5wVtB5VL8rJQkj9RLszJTNk1sojmgskREUXP4eeAv94lL/oasPAi4N33Ays2qBdXkhkYHsP7m1+At70vpL6iMBtCRSGEBQXyV0Uh1iwoQEVBDopyMznehyhKmBwR0fwN9QCub8mDrgO02XL32bWfBzLZTTOT4VE/dh3ywbX/NBytx9AzJE+euKQkF9b/uBSXLdehJJ8zfxPFA5MjIpqfN53Ao18Auo9N1C3fALznJ8DCC1QLK1FJkjyD9Bune/Hm6R68cboHb5zuxRune9A/HLqAbnamBr//+EasXVikUrRE6YnJERHNzVAv8PcvyzNbB2TlA5vvATbWAhrObRNwpKMfj758Ak8dOIPXT/UorUJTydRkYMPqMnzeuI6JEZEKmBwR0eydfQNouRNof32iTnibPLaodLVaUalucGQMJ8QBHO0cwLHOfhz1DeB5Tzv2HguzTtw5lunysHFNGTavX4jr1y1ASR670IjUwuSIiGbntb8Aj3waGO6Vt3OKgZu3ApffkTbzFQ2OjOGJ107jjVM9ONrZj2PjydDp7pkfs1+my8O6RYU4b1ER1i2Uv69dWIiCHP5zTJQo+NdIRJGRJHkyx6f+e6Ju4YVAzQNAuV69uOKovXcIv3v+MP7wwuFZLbFx4ZJi3HrZEtx6yVKsLM+PYYREFA1MjohoZqPDwKOfB/Y+OFF3iVnuRssuUC+uOJEkCQ/vPo57/voqegbDjxeqKMzBirI8ZWbpFePfhQUFWF7KhIgomTA5IqLpDYjy+KJDz0zUme4DrvlcSnejjYz50XqoE08eOI0nD5yB5+zEnENaTQbedckS3HbZUqyuyMcyXT7ysjkAnShVMDkioql1nwB+/z7g7AF5OzMXeJ8NuOi9qoYVK2N+CS94O/CQ+zieeO1U2Fai912xDHffdD6W6vJUiJCI4oHJERGF5zsI/O42QDwsb+eXAx/4E7Bio7pxxcjvnz+Enz7lwanuwUn7NBmAYWUp6m4Q8I6LFqsQHRHFE5MjIprs7OtyYtRzUt7WrQI+/AhQJqgaVjT1DI7gZNcgTogDcB8R8aMdb4bsL8rJxI3rF+LGCxbihnULuBgrURphckREoc6+DvzmVqDvjLy94ALgQw8DxUvVjWsOAo/cH2rvw8muAZwQB3GyawAnxcEpJ2LMyAB+8gEDNq9fiNwsjiMiSkdMjohowtk3QhOjJZcBdz4MFJSrG9ccNT60Dw/vPh7x8dmZGvz9c9dxVmqiNMfkiIhkvoPAb98dmhh9+C9AXqm6cc1BR+8Qfuh6I2xilJ2pwdKSXCwpycMSXS6WBn2/eFkJFhTlqBAxESUSJkdEBPSeBR64Heg9JW8vvhT40CNJlxh5zvbid88dgr3tWMgirpsvWIj/NJ2HJSW5KCvIRkYKT0FARPPH5Igo3Q31Ag+aAZ9X3l5wgdxilF+mblyzMDA8hi/Z9+Dv+06F1OdlaVG/ScDnblwHjYYJERFFhskRUTobGwG2fxg4sVveLloK3PnnpEqMAOCrD+8LSYzysrQwVy3HZ9++FguLc1WMjIiSEZMjonQlScBf7wI8O+Tt3BLgQw8BJcvVjWuW9p/sVsYW5Wdr8Z/G87ClagVK8rmqPRHNDZMjonS1415g7x/lsjZHnuBx4Xp1Y5qDJw+cUcr1N+hRe0PqzMVEROpgckSUjl74BfDsD8c3MoD/+CWw6hpVQ5qN4+IAnnj1FB5/9RRe8PqU+k3nL1AxKiJKFUyOiNLN/keBf35lYvuW7wEXvke9eCLU2TeMx/adxF92H0fr4c5J+9dUFODSZSUqREZEqYbJEVE6OXMAePiTACR5+/ovAxs+oWpIMznq68f9O97EI7uPY9QvTdq/ujwfN120GB++ZjWfSCOiqGByRJQuBruAljuA4V55++Jq4MavqxvTOEmS0N47jGOd/TjWOYCjge++frzg7cDIWGhStG5hId592VLcfPFirFtYyHmLiCiqmBwRpQO/X24x6nhL3l50MfCeH8sLianghDiAB144jNdOduNY5wCOdfZjcMQ/7WuKczPx/o0rcdvlS3HhkmImREQUM0yOiNLB098FXv+7XM7VATUPANn5cQ/D1zcM6z8O4KHdxya1Bk1Fl5+FD121Cp+4XkBJHh/PJ6LYY3JElOreeBz419bxjQyg+ldA2RpVQvnUA2148aAvpC43S4PlpflYXpqHFePfle2yfJTmZ7GViIjiiskRUSrr8AB/roUyAHvzN4C1RlVCOdjeF5IYffbta/HBK1diSUkukx8iSihMjohS1VAv8KcPAkNd8vb6dwPXfVG1cJ59q10pf8G4Dl8wnqdaLERE02FyRJSKAkuDnD0gb1ecD7z356oMwPb7Jfz9lZO43/WmUrdhdXKt3UZE6YXJEVEqavsN8OpDcjmnGHj/g0BOUcwv2zUwgiMd/Tjs68Phjn4c7uhD2+FOeM72Kcdcu7YcVwvlMY+FiGiumBwRpZrTr4bOgH3bT4CKtVG/zOiYHy2tR/GC14cjHX047OuH2D8y7Ws2ri7Dj95/BSdrJKKExuSIKJWMDACOjwGjg/L2hlrgwtuifpkDp7pxt/1l7DveFdHxVatK8bnN63D9ugoOviaihMfkiCiV7LhvYpzR4kuAd/xX9C+x/zQ+++BuDIyMKXUZGcDSkjysLMvHqvJ8rCzPx6qyAqVcnMv5iYgoeTA5IkoVnqeAF34mlzNzgdt/CWTlRvUSf3zpCL728D4Eljg7b1Ehvn3bxbh8pQ45mdqoXouISC1MjohSwUAn8MinJ7aN9wILL4ja6Q+c6sZPnnwLj718Uqm79dIl+J75MuRmMSkiotTC5IgoFfzty0DPCbksvA3YWBeV00qShPseew2//vehkPra69eg8Z3rObCaiFISkyOiZLfPAbzikMu5JcBtPwM0mqic2t56LCQxKi/IxpfecT4+eOXKqJyfiCgRMTkiSmZdx4G/Bc16fcsPgJJl8z7tya4B/M/fD+DRvSeUuurK5bjvtouQn81/NogotfFfOaJk5fcDj3wKGBx/nP7iauCS6nmf9q97T+DrD+9D9+CoUle1qhT//b6LOeiaiNICkyOiZPVSM3Bwp1wuWgrc8r15n7Jl1xFY/rxP2S4vyMbnjevwgY0rkaWNTlcdEVGiY3JElIzOHABc90xsv/dnQF7pvE759Btn8Y2/vKps33b5Utz3notRks85iogovTA5Iko2o8PAQ7UTs2Bf+SlA//Z5nXLPURGf+G0rhsf8AICPXL0K99528XwjJSJKSkyOiJLNTitw6mW5XHE+YLxn+uOncVwcwIveDnxx+16lbvMFC/G1Wy6cb5REREkrKZIjl8sFp9MJvV4PURQBAA0NDbM+j8PhgNPpDKmzWq3Q6XRRiJIoDk7sAZ79oVzWZAK3NwNZebM6xZmeQdzvehNPv3kWR30Dk/b/+INXIDuT44uIKH0lfHLkcDjQ0tICu92u1LlcLphMpkmJznQsFgtMJhNsNptS5/V6sXnzZuzYsYMJEiW+0WHgL58BpPE1zW64G1h6ecQv7+gdwrNvteO//rYfZ3uGJu3P1mrweeM6PqpPRGkvof8VFEURtbW1OHjwYEi90WiExWJBc3Mz6upmngnY7XYrrwsmCAK2bduG2trakOSLKCE9+0Pg9CtyedHFwHVfnPbwMb8E1/7TeO6tdrzg9eH10z0h+7MzNbhihQ5XCuW4SiiDYWUplwIhIkKCJ0fbt2+HIAhhW3Vqampgs9kiSo5cLhc2bNgQdp/BYFCSJ6KEdfpV4OnvyuUMLXDbT4HM7CkPHxnzo/73bXjywJmw+69dW477338FKgpzYhEtEVFSS+jkyG63o6ysLOw+QRDgdrshimJEXWI2mw3V1ZMnyPN6vRAEYb6hEsWOf0zuTvOPyNvXfWHa7jRJkvDVh/aFJEaaDOCSZSW4SijHNWsrcP3aCq6LRkQ0hYQeddna2jpl4hKo93q9M56nuroaLpcLZrNZGdAdYLVaYbFY5h0rUcy8aANO7JbLFecDN0z/MML/ut6Eve0YAHkc0f3vvxx773kH/vLZ69D4rvXYdN4CJkZERNNI6OQoklahSJIjQRBgtVrhcDiwZs0auFwuAEBzczNMJtOksUhECUM8Ajz5XxPb7/kxkJU75eH21qO4f8ebyvYPai7DbZcvQ1EuJ3IkIopUQnerTSeQNPl8voiOb2hogCAIMJvNMJlMEAQBTqdzxi61oaEhDA1NPNnT29s755iJZkWSgL99GRjpk7erPg6svHLKw/uHR/Htx15Ttr9+y3rceunSWEdJRJRyErrlKNp0Oh0aGhpgNBrh9XphMplmHIy9detWlJSUKF+bNm2KU7SU9l59GHjzcblctGTGyR7/se+UsljsLZcuwSeu51g6IqK5SNrkKDB2aKoB2+eyWCwQRRFWqxVOpxM2mw1erxeVlZVKN1s4jY2N6OrqUr527twZjfCJpjfQCfwjaCzcu74L5JZMefjgyBh+89whZfsjV6+OXWxERCkuabvVZqO5uRkAQp5Wq6urg9FohMlkgtlsxsGDB8OOb8rJyUFOzsTjzoWFhTGPlwjOe4C+8afNLrgVWP/ukN1ne4bQdtgH9xERbYc70Xa4U9m3sCgHl6/QxTFYIqLUktDJkSAIUw64Dow1iuQxfKvVCo/HE/b8bW1tyiDtcI/6E8XdoX8D7t/K5ewi4J1NIbu37zqKxof3YcwvhX15U/WlXP6DiGgeEjo5MhgMkx69DwgkTQaDYdpzzPTEm06nQ2NjY0RPvRHF3OgQ8OjnJ7aN9wAlywDI8xe1Hu5Ew59fnvSyNRUFMKwshblqOa4SyuMVLRFRSkro5MhkMsFqtYbd5/F4InoEX6fTTZlgBeNEkJQQnvkB0DH+KP7yDUDVxwAAO/afxn2PvYbDHf0hh2/7cBUMK3Uo50zXRERRk9Bt71u2bIHP5wvbquNwOFBfXx9SJ4pi2MHVgiBMO+ja6XRyriNS35kDwDPfl8uaTODd9wMaLQ619+FTD7hDEqOCbC2+fdtFMF24iIkREVGUJXRypNPpsG3btkkzWDscDgiCMGmMUGAOo8AA7AC73Q6LxTIpQRJFEfX19bBYLBEtQUIUM34/8NgXJpYIufbzwKKLAAC//vdBDI/5AQBCRQF+WHMZdn3diA/xiTQiophI6G41QH7CTKfTwWKxQK/XK11kTqdz0rEmkwmtra2oqqoKqdfpdGhra4PFYoHdbg/ZZ7VamRiR+vY+CBx5Xi6XCcANdyu7jnYOKOVffqQKwgI+MUlEFEsJnxwBgNFojKjbq6GhAQ0NU687NdX4JSJV9fsA5zcntm/5Pnr9Wdix5zj+vu+ksoBsdqYGS0ryVAqSiCh9JEVyRJTSdtwH9HfI5Ytux3O4FLX/7ULf8FjIYTeevxB52VoVAiQiSi9MjojUdKwVaPuNXM4uQvcN9+Irv90XkhhVFGbjnRcvwV2b16oTIxFRmmFyRKQW/xjw2H8CkCdz9Fx8F7Y0v46OvmHlkD/WXoWNa8qg1WSoFCQRUfphckSkll2/Ak7JEzpKCy+C2X0pfINyYpSfrUXzh6pwtZ4TOhIRxRuTIyI19JwGnvy2svnjvE/BNyg/rl9RmI1H77qOg6+JiFSS0PMcEaUs5zeAoW4AwDOFN+MHr5cpu5qqL2ViRESkIiZHRPF28Bng5RYAQL+2GJ9rfy8AIFurwXerL8WNFyxSMTgiImK3GlE8jQ4Df/uSsnnf4BZ0ohgA8NuPbeQYIyKiBMCWI6J4euGnQPvrAIDXM89Hy9jbAABXC+VMjIiIEgSTI6J4EY8AO5sAAH5o8MW+D0OCBvnZWnzpHeepHBwREQWwW40oXv7ZCIz0AwB+O2rCq9IaFOdm4sHaq3DxshKVgyMiogC2HBHFWEfvEJ569PfAgccAAGelEvxg1AwAqN+kZ2JERJRgmBwRxVD/8Cje80Mn9LvuVeq+PXInepCPTE0Gbr54sYrRERFROOxWI4qh1050Y8uQAyszzwIAXpQuQpf+Nlj0FbjpokUQFhSqHCEREZ2LyRFRDO3e04pPah8FAIwiE5Wf+hV+u3i9ylEREdF02K1GFCNd/cNY2/ZfyMkYBQAMVn0SmUyMiIgSHluOiGLgwReP4Pl//B4/1u4FAHRoK1D+jq+qHBUREUWCyRFRlP3xpSO49+E2OLN/rbTNdl1/D8qzC9QNjIiIIsLkiCgKhkbH8Nc9J/DgS0ew+4iIu7SPYaVGHoQ9tPxaCJs+pHKEREQUKSZHRFHw2Qd3w/naaQDA8oyz+EzmXwAAUoYWOe/5PpCRoWZ4REQ0CxyQTRQFO984q5S/U/gn5GaMAAAyrvwksJCDsImIkgmTI6J5etHbgeFRPwDg5tzXcN3I8/KOgoXA2ywqRkZERHPB5Ihonra3HgMAZGEUTQV/mNhhug/I5dIgRETJhskR0Ty94O0AANRmPY7ivoNy5YorgUtrVIyKiIjmiskR0Twc9fXjuDiAhejEXZkPjddmAO/6LqDhnxcRUTLiv95E8/DMm+0AgMasB5EnDciVVR8DllymYlRERDQfTI6I5sjvl/DLZ73YmLEf79P+W67MKwNu/Lq6gRER0bxwniOiOWo93InDZ7vx0+zfTlRu/iaQX6ZeUERENG9sOSKao+anvbhD68J6zRG5YsnlgOHDqsZERETzx+SIaA7ae4ewe/8b+FKmfaLyXd8DNFr1giIioqhgckQ0Sy96O3Dz/z6DuzNbUJLRL1defgewYoO6gRERUVQwOSKahefeasedv3oRy/pexfsz/wUAGM0qBIzfUjUuIiKKHiZHRBE6cKob9b9vw+jYGO7L+o1Sn7n560DhQvUCIyKiqGJyRBSBE+IAPvp/u9AzNIot2p24TOOVdyy8ENhQq25wREQUVUyOiGbQNTCCj/76JZzqHkQJevG17JaJne9sArScEYOIKJUwOSKaht8v4VMPtOGN070AgHsKH0Gx1C3vvPg/gDXXqxgdERHFApMjomk8eeAMnvPIC8telX8c7xv7p7wjqwAwfVvFyIiIKFaYHBFN4Y3TPfjKQ/vGtyT8qORBZEh+eXPT3UDJMtViIyKi2GFyRBSG3y+h7netaO8dAgB8qGAXFnbulneWrwWu+rSK0RERUSwxOSIK462zvTjUIU/weFGFFvfkBg3CvtkKZOaoFBkREcUakyOiMNoOdyrlb5c/gcy+k/LGeTcD64wqRUVERPHA5IgojN1H5ORoRcZpXH7093KlJgu46X9UjIqIiOKByRFRGC8f6wIAfCPrD9D4h+XKqz8NlOtVjIqIiOKByRHROR5yH8OBUz24VrMP79C0ypWFi4Ab7lY3MCIiigtO7Us0TpIk/HynB999/HVkYhT3ZP5uYqfxW0BOkWqxERFR/DA5Ihr3j1dOoemfrwMA7tS6cJ7muLxjWSVw6ftVjIyIiOKJ3WpEkOc1+vm/PACAMnTj7pyHJna+swnQ8E+FiChd8F98IgD3PfYa9h2XB2F/OXM7CvzyWmq47IPA8ioVIyMionhjckRp74Q4gN88dwgAcFHGIXwg8yl5R3YRYLxHvcCIiEgVSTHmyOVywel0Qq/XQxRFAEBDQ8OczuX1emGxWAAAZWVl0Ol0sFqt0QqVkswJcQAf+82u8S0JPyn9EzL6JXlz091A0WLVYiMiInUkfHLkcDjQ0tICu92u1LlcLphMJjidzlmfa+vWrbDb7RAEAQAgiiIsFgsTpDT0t5dP4isPvYyewVEAwAfzd2FN/8vyzjI9cOWnVIyOiIjUktDdaqIoora2Ftu2bQupNxqN8Pl8aG5ujvhcbrcbtbW12LFjh5IYAUBtbS0cDkfUYqbksPtIJz77R7eSGOlLMnBffvD6aVuBzGyVoiMiIjUldHK0fft2CIIAnU43aV9NTQ1sNlvE57JYLGhsbJx0LpPJhPr6+nlGSsmkZ3AEjQ/tgzTee3bzRYvxt8pWZPaOr5+21gScd5N6ARIRkaoSulvNbrejrKws7D5BEOB2uyGKYtjkKZjb7YbL5Qrpmguoq6uLRqiUJN443YMvbd+LA6d6AADrFhbiJ+8sQ+bPfyIfoMmUW42IiChtJXTLUWtra0gXWLBAvdfrnfE8NpttyhYoSh+u107j1h89qzyyX5KXhZ/fWYnMHd8Axobkg678JFCxTsUoiYhIbQndchRJq5DX64XBYJj2GJfLpSRTTU1NAACdTgePxxO2q41S02+fP4ThMT8AYHV5Pn7yQQPW9rYB+x+VDyhYAGya21OQRESUOhI6OZpOIKHx+XwzHhtIoJqamkKmAPB6vaisrERbWxsTpBTX2TcM9+FOZfufX7gBuRoJsH1l4qDN9wC5JSpER0REiSShu9Wiye12o7q6OqROEAQYjUbU1tZO+bqhoSF0d3crX729vbEOlaKse3AEn/hdK/qGxwAAH9i4ArlZWqD1/4Azr8kHLb0CuPwOFaMkIqJEkbTJUWAyyKkGbIcTbvxSZWUlHA6Hcr5zbd26FSUlJcrXpk2b5hIuqeirD+1D23irUVFuJj79trVAvw946r8nDuL6aURENC5tPg1mGtjd2toadn9jYyO6urqUr507d8YsRoq+595qx2Mvy4/oF+Vm4o+1V2FFWT7wr+8Ag6J80KU1wIqN6gVJREQJJaHHHAmCMOXTaIGxRlMlPeeeJ5KB3eHk5OQgJydH2S4sLJzxepQYBobH8GX7XmX7K++8ABcvKwHOvg7s+qVcmZUPGL+lToBERJSQErrlyGAwTNndFUhmZnpSLXDMTI/8V1Vx5fVU4vdLsP7zAE50DQIArhbK8YENK+WdT3wdkOTxR7j2C0DxUnWCJCKihJTQyZHJZJoyqfF4PDAajRGdp6amBm63O+y+wPkjaYGi5NA9OII7f/UifvPcIaXua7esh0aTAby1A3jzCbmyeBlwzV3qBElERAkroZOjLVu2wOfzhU2QHA7HpGU/RFGEy+WadGx1dTV0Ol3YNdTsdjvq6ur4KH8K+a/HXsNzng5l+64b18rdaWOjwONfmzhw8z1Adr4KERIRUSJL6ORIp9Nh27ZtsFgsIfUOhwOCIEx6NN9sNsNkMoVdkNZut8NisYR00zU3N8Pr9cJqtcYkfoq/U12D2N56DACQl6XFAx+/El96x/nyTvdvgbP75fJSA3CJWaUoiYgokSX0gGxgotXHYrFAr9cryY3T6Zx0rMlkQmtra9jxQ0ajETabDbW1tSgrK4PP54MgCPB4PLH+ESiOvGcn5qEyVy3Hdesq5I3BLuCp/5k48Obv8NF9IiIKK+GTI0BObCIZX9TQ0BAyA/Zcz0PJKzAAGwCEioKJHU9/D+hvl8sX3Q6svDLOkRERUbLgf50ppRzu6FPKS3R5csHnBV78hVzW5gCme1WIjIiIkgWTI0oZLx8T0fz0xOB9/YLxliPnN4GxYbl89WcA3UoVoiMiomTB5IhSgiRJuO/R1zA06gcA3G5YhrULi4BDzwL7H5UPKlgIXP9FFaMkIqJkwOSIUoK99Rhax9dPW7uwEN+5/VLA7wce/+rEQZu/AeQUqRQhERElCyZHlPRGxvz4n3/sV7YtN1+A7EwNsPePwMnx5UMWXwJcfodKERIRUTJhckRJ72B7H8T+EQDA9esqYLpwETDUC+y4b+Kgm/4H0GhVipCIiJIJkyNKeh29w0r5wiXFcuHf9wO9p+Ty+bcAa25QITIiIkpGTI4oqUmShL/uPa5sl+RnAV3HgOd+LFdosoB3fFul6IiIKBklxSSQROGM+SXc9Uc3/r7vlFJnXL8IePJuYHRArriyHijXqxQhERElI7YcUdI6cKo7JDH6ouk8nOc/COz9k1yRqwNu+LI6wRERUdJiyxElrd7BUaV83doKfG7zOuD37wMgyZWbGoC8UnWCIyKipMWWI0pKZ3uG8PVHXlG2bzivAnhrB+B5Uq7QrQQ2fEKl6IiIKJmx5YiSSnvvELY948Xvnz+M/uExAECWNgObz68AHvrIxIGb7wEyc1SKkoiIkhmTI0oar53oxge2vYCugRGlrqIwB/e//3LoT/4dOL1PrlxyOXDR7eoESURESS/i5OjJJ59EWVkZdDodVq9eHcOQiCYbGB5D7e9alcQoW6vB+zeuwF03rsOCXD/w4/+aOPgd3wY07DEmIqK5iTg5qq6uRldXFwwGAwRBQFlZGUwmE26/nf9Dp9h79q12HBflx/PXLynGrz+6AYtLcsd3/i/QfUwur7uJEz4SEdG8zKpb7Re/+AVqa2tjFQvRlJ7ztCvl/3fN6onEqN8HPPMDuZyhAYzfin9wRESUUmbV98DEiNTg90v49b8PAQCyMzV42wULJnY+/V1gqEsuX34HsOjC+AdIREQpJeKWI0EQYhkHUVj/ev0Mvvv468r2htWlWFg03mrkOwi8tE0uZ+YBb/+qChESEVGqiTg5Ki8vn1S3Y8cOHDx4EEajkYO0KersrUdxt+PlkLqr1gS9D5/8NuAff3Ltms8CxUvjGB0REaWqeT3Ss3nzZlRWVqKurg7l5eWoqanBL3/5Sxw6dChK4VE6c752WikX5Wbiu9WX4jNvXytXHG8DXvmzXM6vAK75nAoREhFRKpr3885XXHEFnnjiCUiShA0bNqCyshIejycasVEae+N0D548cEbZfrbhRpirVkCjyQAkCXDeM3Hw274C5BarECUREaWiqE0CKQgCvvxlLvJJ0fHw7uMY9ctrpH3s2jUoyc+a2OnZARx6Ri6XCUDlR+MfIBERpayIW448Hg+eeuqpKfeXlZVFJSAiADgxPqcRANx51cqJHX4/sOO+ie0bvwFogxInIiKieYo4OfL5fDAajdBqtbj55pvxve99D3v27FH2Z2RkTPv64GOJpjPml/DysS5le2Fx7sTO/X8FTu6Vy4svBS58b3yDIyKilDerMUebN2+GJEl44oknYLFYUFlZCa1Wiw0bNqC1tXXaliWLxTLvYCk9/PrfB3GwvQ8AcMmyEhTmjPf+jo0CTwYtE7L5m1wmhIiIoi7iTxZBEPDEE0/A7/ejra0N3/nOd3DjjTdCkiS0tbWhs7NTaVnauHEjvv/977O1iGbtcEcfvvOPA8r2125ZP7Fz7x+Bjjfl8sprgLXGOEdHRETpIOIB2TU1NUr5iiuuwBVXXIG7774bALB79264XC488cQT2LFjB1pbW9HW1qYcbzAY4PV6oxg2paoXvT5lIPZHr1mNq4TxeY1GBoF/fWfiQOM9wAxduURERHMRcXIUSITCmSlZamtrm3FMEhEA+PqHlfKVa4IG+bf+X+jisiuvinNkRESULmIyYCOQKDmdTvj9fjzxxBPQ6XSxuBSlmD1HRKVcVpAtF4Z6gGe+P3HQjV+Pb1BERJRW4jKa1Wg0orKyMh6XoiTVNzSKu+178c9XTwEAsrUaXLK8RN75ws+B/na5fPF/AEsuVSlKIiJKB1GbBHImBoMhXpeiJOPrG8b/+80u7D0qKnUfu24N8rMzgX4f8NyP5coMLfD2r6kTJBERpY24JUff+c53Zj6I0tIXt+9REqPCnEx8890Xwly5XN757A+AoW65fMWdQLlenSCJiChtxC05IgrnTPcgdr5xFgBQkK3Fnz91Dc5fXCTv7D4BvLRNLmtzgE2cK4uIiGKPM+iRqn717EFI8pP7+Oi1qycSIwB4+nvA6KBc3lgLlCyLf4BERJR2mByRakbG/NjeehQAkJ2pwYevXj2xUzwCuH8nl7MLgeu+GP8AiYgoLTE5ItU87+lAZ/8IAMB04SIsCl5D7envAX55H676FFBQrkKERESUjpgckSokScKvnj2obN96yZKJnb6DwJ4/yOWcYuDqz8Q5OiIiSmdMjkgVO/afUQZiLy7OxdsvWDix8+nvAf5RuXzVp4G8UhUiJCKidMXkiOJOkiTcv+NNZfub774QuVlaeaPDIy8wCwC5JXKXGhERURwxOaK4e+bNduw73gUAuHBJMd558eKJnU9/F5DG5PLVdwF5uvgHSEREaY3JEcXdM2+eVcr1m4SJRYnb3wRebpHLeaXAlfUqREdEROmOyRHFld8v4ckDZ5TtDavLJnbutAKSXy5f8zkgtzjO0RERETE5ojjbf6obnrN9AADDSh2W6vLkHWcOAPsccjm/HNhYp1KERESU7pgcUVyd7RlSyteurZjY8XQTgPGpsq/9PJBTGN/AiIiIxjE5org6IQ4q5dL8bLnQ/ibwykNyOb8C2PAJFSIjIiKSMTmiuNlzVMQPnG8o2xcE1lF75vtQWo2u+SyQXRD/4IiIiMZlqh0ApYedb5zFx3+zC6N+OQm6eFkxrtaXAz4v8PJ2+aC8UrYaERGR6thyRHHxt5dPKImRUFGAX9xZKT/C/8wPJuY1uuozQE6RilESERGx5Yji5GB7n1J+sPYqLC7JBcQjE7Nh55QAV/IJNSIiUl9SJEculwtOpxN6vR6iKAIAGhoa5n3epqYmGAwGGI3GeZ+LpnbU14+2w50A5FajxSW58o5nfzixhtqV9fJyIURERCpL+OTI4XCgpaUFdrtdqXO5XDCZTHA6nXM+ryiKsFgsIeel2PjeE69jvEcN771imVzoOg7sfkAuZxdyDTUiIkoYCT3mSBRF1NbWYtu2bSH1RqMRPp8Pzc3Ncz73fF5LkXMf6cRf9pwAABTnZuLDV6+Sd/z7fmBsWC5v+ASQXzbFGYiIiOIroZOj7du3QxAE6HS6Sftqampgs9nmdF6Xy8WutDhwH+nEB5pfULY/e+Na6PKzgZ7TgPu3cmVWPnD1Z1WKkIiIaLKETo7sdjvKysK3KAiCALfbrYxBmg232w2DwTDP6GgqkiTh64/sw+0/ew5Do36l/vp1C+TC8z8GRscng6z6GFC4QIUoiYiIwkvo5Ki1tRWCIITdF6j3er2zOmdzc3NUBnNTeH6/hJ/v9OCBF44odUtLcvHd6kuxfkkx0O8DWn8t79DmANfcpVKkRERE4SX0gGxRFMN2qQXzer0RtwJ5vd4pW6Jo/s50D6L2923Ye1RU6r5gXIdPv20tsjPH8/BdvwKGe+XyFXcARYvjHygREdE0Ejo5mk4gafL5fBG/xuFwzLrVaGhoCENDE4ul9vb2zur16eTex14LSYw+es1qfH7zOnmyRwAY7gde/LlcztCw1YiIiBJS0iZHs+VwOFBdXT3r123duhX33ntvDCJKLX6/hKdfP6tsP1h7Ja7RV4QetPsBoL9DLl90O1AWvsuUiIhITQk95mg6gYHYkXSTiaIIn8835fil6TQ2NqKrq0v52rlz56zPkQ6OdQ6gZ0ie0PHt5y+YnBiNjQDP/Xhi+7ovxC84IiKiWUiLlqP5DMLOyclBTk6Osl1YWBitsFLKH148rJTXLymefMArDwFd44O015qAxZfEKTIiIqLZSeiWI0EQpnwaLTDWaKbWID62Hx//fPUUACBbq8FHrlkdutPvl5cKCbjuP+MXGBER0SwldMuRwWCYch6jQNI0U+Lj9XrR0tIyacLIwHm3bt2KlpYWlJWVzXlSyXTXOzSKwx39AIBLlpdgUXFu6AFvPgGc3S+Xl28EVl0T5wiJiIgil9DJkclkgtVqDbvP4/FENMt1dXV12IHYoiiitLQUjY2NcxqoTRMOd/Qp5SUluZMPOLfVKPD0GhERUQJK6G61LVu2wOfzhe1aczgcqK+vD6kTRREulyte4dG4Z99sV8pVq0pDdx5+Hjg6voTIgguA826OY2RERESzl9DJkU6nw7Zt22CxWELqHQ4HBEGY1OJjNpthMpkiWlQ2kHDNZp4kCu9U96BSvnBpSejO4Faja78AaBL6LUdERJTY3WqA3C2m0+lgsVig1+uVsUJOp3PSsSaTCa2traiqqpryfG63G1u3blWSI4vFAqfTCZPJhLq6upj8DKmsZ3AET7x6WtleXZ4/sfPUK8Cbj8vl4uXAJey+JCKixJfwyREAGI3GiMYXNTQ0zPjIvsFggN1uj1Zoae8rf96H4+IAAGDjmjIsDB6M/e/7J8rX3AVos+IcHRER0eyxj4PmrH94FH/bdxIAkJOpwXduD5q7qPMQ8Mqf5XJ+OWD4cPwDJCIimgMmRzRnv3rmoFJ+1yVLICwImiDzuZ8A0phcvvKTQHY+iIiIkgGTI5qT5z0d+N8dbwIANBnAh65eNbGzr0NeRw0AsgqADZ9QIUIiIqK5YXJEs3aqaxB3/dGNMb8EAPjs29fCsDLoEf7WXwGj8jgkVH4EyJ95/TsiIqJEweSIZq3p8QNo7x0GAFy/rgKfN543sXNkEHhpfCqFDI3cpUZERJREmBzRrO0/2aOU73//FdBqgma83rcd6Dsrly+8DShdBSIiomTC5IhmpXdoFAfbewEAi4pzUFaQPbFTkoDnfzqxffVdcY6OiIho/pgc0az80PkGBkf8AIAbL1gUuvMtF3D2gFxeeTWwvDLO0REREc0fkyOalUd2H1fKn9wkhO587scT5as/G6eIiIiIoovJEUWsq38EHX3yQOwLFhdhVXnBxM6TLwMHd8rlMgE4/50qREhERDR/TI4oYn/dO9FqtHHNOY/nB481uurTgEYbp6iIiIiii8kRRexk16BSfvsFCyd2dJ8AXnHI5bwy4PI74hwZERFR9DA5ooidCkqOFhUFLTD7og3wj8rlDR/nUiFERJTUmBxRxNxHOgEAWdoMCAvGxxsN9QBtv5bL2mxgQ61K0REREUUHkyOKyLHOfhzq6AcAXLGyFLlZ42OKdj8ADHbJ5Uu3AEWLpjgDERFRcmByRBF57q0OpXytvkIujI0CL/xs4iA+vk9ERCmAyRFFZNchn1K+dm25XDjwKCAekctrjcDC9SpERkREFF1MjigifcOjSnmpLk8uhCwVwlYjIiJKDUyOKCJHfQNKuSQvCzj6EnBsl1yx6GJAeJs6gREREUUZkyOaUdthH/Ydlwddr6koQEFOZuhYo6s+DWRkqBQdERFRdDE5ohk9svuEUv7kJgEQjwKv/VWuKFgIXFKtUmRERETRx+SIpnW6exB/dh8DAGRrNbj10qXASzZAGpMP2PAJIDNHxQiJiIiii8kRTWlwZAx1v2tF/7CcCG3ZsBwFGATaficfoM0Bqj6mYoRERETRx+SIpmRvPYq9x+SxRktKcvEl0/nAngeBocCkj2agcIGKERIREUVfptoBUOJ64eDE3EZbb78EpXmZwIs/nzjgqk+rEBWRzOVywel0Qq/XQxRFAEBDQ8OczuX1emGxWAAAZWVl0Ol0sFqtMb1mJJqbm+HxeFBeXo6ODnki1nBxqS1W96WpqQkGgwFGozFu1yQCAEg0K21tbRIAqa2tTe1QYupM96C09qt/k1ZZHpMuueef0uDIqCTt/5sk3VMsf/32PWqHSGnMbrdL1dXVIXVOp1MyGo1zOpfBYJA8Ho9S19nZKTU0NMTsmpFoaGgIiUmSJMlqtU6KQW2xui+dnZ0SAMlut8ftmpTaZvP5zW41CuuJ105hZEwCAHxg40rkZGonP75PpAJRFFFbW4tt27aF1BuNRvh8PjQ3N0d8LrfbjdraWuzYsQOCICj1tbW1cDgcMblmJOrr69HY2BgSU+B6wXGpLZb3ZarXxvt3QemJyRFN0j04gv91valsv+OixcDJl4FDz8gV5euAtSaVoqN0t337dgiCAJ1ON2lfTU0NbDZbxOeyWCxobGycdC6TyYT6+vqYXHMmDocDZrM57LW8Xm/UrhMNsbovLpcrbFdaLK9JFIzJEU3yr9fP4mzPEADgurUVMKzUAS8EjzX6JKDhW4fUYbfbUVZWFnafIAhwu93KGJTpuN1uuFwu1NXVTdpXV1cXMn4lWteMhNPpnDIx2Lp1a9h41RKr++J2u2EwGOJ6TaJg/ISjSU6IE0uFbNmwAhm9Z4BXxpvyc3XAZR9QJzAiAK2trZO6mwIC9ZG0sNhstilbIGJ1zZm43W6YTOFbZZuamgAgoVpGYnFfmpubpx1YHa/fBaU3Pq1Gk3jO9CrlpSW5QOsvgLFhuaLyo0B2gTqBUUyIooitW7dCFEXo9Xp0dHRAr9cnVAtFMFEUZ0xovF7vlC0PAS6XS/kwDSQeOp0OHo9nUldbtK45k5aWFuVpNJPJBJ1Op3zQC4KAtra2eZ0/2qJ9X7xe75StQrG6JlE4TI4oxODIGP6+7yQAIC9Li/MrsoDtv5J3ZmiBjYn5gUlz43a7YTabYbPZQrpyAo9HB/8Pvrm5OWETpoDAh6bP55v+QEx8gDY1NYX8nF6vF5WVlWhra4uoVWk215wNs9kMURRRU1MDn8+XUC1GkZjLfXE4HPN6HD9WvwtKP0yOKMSprkH0jc+IfcN5FSh642Ggv13eedF7gZJl6gVHUeV2u1FZWQm73T5pjIvVaoXZbEZdXR10Oh3cbveM/6MH5KesXC7XnOKpr6+P+zw1brd70rxBgiDAaDSitrYWdrs9rvEEOzcRtdvtsFgsEc9zlGy/C4fDgepqrtNIiYHJEYXwnJ3oUltVlg88H/z4/mdUiIhixWw2w2g0hv1ACnQ3uVwuVFdXh3T3TEft1o3AQNxIErmAcONXKisrUV9fH1EXzlyuGY7L5ZpyvBEgd7PZbLaIk6Nk+l2IogifzzflWKJYXJNoOhyQTSH2n+xWyjfmvAac3S9vrLgSWF6pUlQUbU1NTfB6vSGPqwcLHtjq9XpRXl4ez/DiZqaBva2trXGLZbqn1ACgo6MjZQcaJ0OXLaUXJkcU4rg4qJQvPPzAxI6rPqVCNBQrLS0tADBjN0ZHRwdsNltCLcsgCMKUSUJgrEkkLRCRPKkWPBg6GtecD6/XG9EYqHiKxn2Z7rH9WF2TaCbsVqMQgW41fcZxFB99Sq4sWQlc8G4Vo6Joc7vdEX2AOBwOVcfdhGMwGKacxybwoRnJh63BYJixJaaqqiqq15yP6SZGVEs07ovX60VLS8ukbsDAebdu3YqWlhaUlZXBZrMlxO+CUh+TI1Ic6ejHrkPy/7zuKtgBjI7vuLIO0PKtkkp0Ol1EyZHRaJzVB008BgGbTKYpx914PJ6IE4iamhqYzeaw+4JbjKJ5zam4XK5puy4dDgdEUURjY2PE50yW30V1dXXYFkxRFFFaWorGxsaQ/bH+XRAB4MKzs5XKC8/e85dXpFWWx6RLLX+Shu9dKC8w+99LJWlAVDs0ijKj0TjtIp12u10CMGnx1UTQ2dkp6XS6SYuySpIkCYIwaaHSzs5Oyel0hj2XTqcLu7Cp0WiU6urq5nXNcOeditVqDbneuefS6XSSzWaL+HzxEs3fRbhzI8zCs7O9JlEAF56lWesbGsWf3ccAAB/UPoks//jYo8vvAHJLVIyMYsFqtcLlck3qVhJFERaLBUBot1Nzc3PCLMmg0+mwbds2Jc4Ah8MBQRAmtUKYzWaYTKawC5IGHo8P/tmam5vh9XpDWifmck2z2axMLjmTjo4OZcqEYF6vF5s3b4bVak3IAcvR/F2cK/DeO3fOotlek2gu2FdCGBodwx2/fBE9g6PIxCg+nu0EJADIkNdRo5RjMBjQ1tYGi8UCQRCULh2dTqckBQaDAWazGRaLBXq9PqEGA1dXV0On0ymxBZIbp9M56ViTyYTW1lZl/FAwo9EIm82G2tpalJWVKY+TezyeqFxz165dEf085eXlaGhoQFNTE1paWpTfR0dHB3bs2JFQ9/5c0fpdBLjdbmzdulVJjiwWC5xOJ0wmk5IgzuaaRHORIUmSpHYQySQwcV5bW1vKDPr7/fOH8I2/vAoAqMl9AVb8SN5x/i3ABx5UMTKi5Hbu7NvhuN1u+Hw+jpUhirHZfH6zWy3NDY6M4adPBf6XLOGbFTsndvLxfaKYc7lc07akEFH8MTlKc/945SROdcvjiz655iwK2vfKOxZfAqy+TsXIiJKb1+uN6InAwHgjIkocTI7S3FMHzirl2qx/Tuy46jNARoYKERGlBpvNxsHBREmKyVGaOz3earQy4zTKjj4hVxYsBC6+XcWoiJLbTOukBXi9XmzYsCEOERHRbPBptTQ2OubHgVM9AIBP5fwTGZJf3nFlPZCZo2JkRMkt0sHVgiBwqQuiBMSWozR2qnsQXQMj0KEHt2f8S67MKgCqPqZqXERERGpicpTG9h3rAgDcqXUhRxqSKw0fAvLLVIyKiIhIXUnRreZyueB0OkMm+5rLKuHNzc3weDwh84pMtUZPOvjNc4eQg2F8JPNxuSJDw8f3iYgo7SV8cuRwONDS0hKyMnhgsONsZkO1WCyor69XZlgVRRFmsxmlpaU4ePBg2j1Ke9TXjxcP+vB+7bNYkNEtV174XqB0tZphEREASZIwMjICv9+vdihECUWj0SArKwsZMX6aOqGTI1EUUVtbi4MHD4bUG41GWCwWNDc3R7TekMPhQE1NTcjAR51OB7vdjtLSUpjN5rSbdv509yAy4Eet9m8TldfcpV5ARISxsTG0t7ejp6cHIyMjaodDlJCysrJQVFSEiooKaLXamFwjoZOj7du3QxCEsK06NTU1sNlsESVHu3btCjvfiE6nQ11dnbKoZjq1HvUMjWKzZjf0mpNyxerrgWWpsRwKUTIaGxvD0aNHMTQ0hJKSEhQWFkKr1cb8f8hEyUKSJIyNjaG3txeiKGJgYAArVqyISYKU0MmR3W5HWVn4wcGCIMDtdkeU1DQ3N8PtdodtHaqsrAQAtLa2ptXaRr2Do6jLfGyigq1GRKpqb2/H0NAQVq5ciby8PLXDIUpYhYWFKCkpwZEjR9De3o5FixZF/RoJ/bRaa2vrlHOABOoDKzdPZ7p1iwIDvKdKwlKV/+hL2Kh5HQDQVagH1s48YR0RxYYkSejp6UFJSQkTI6II5OXlobi4GD09PZAkKernT+jkKJJWoUiSI6fTOeWYIo9HXnR1phV6U8nImB+le2zKdvcV9YAmod8KRCltZGQEIyMjKCwsVDsUoqRRVFSk/O1EW0J3q00nkDT5fL55nWemQd1DQ0MYGhpStnt7e+d1vUTwxDPP4Z0jzwMZgC+jFMuu/4jaIRGltcBTabEaXEqUigJ/L7F4qjOtmwssFgsEQZh2rqOtW7eipKRE+dq0aVMcI4yNrBd+DE2G3Aw5YPgENNm5KkdERAA4+JpoFmL595K0ydF8xwq53W40NzfD6XRO23XX2NiIrq4u5Wvnzp1zul7C6DqGtw/KXYy9yMcy42dVDoiIiCixJG232nyZzWbs2LFjxkUfc3JykJMzsQhr0o8JeO7HyMIYAODvebdiS55O3XiIiIgSTEK3HAmCMOWA68BYo7msaG0ymWCz2dJqEDYAoPcMpLbfAAD6pRw8lv8+deMhIiJKQAndcmQwGJTus3MFkqbZJjj19fWwWCxpNaeR4vmfImN0EADw4NiNGMlJr+kLiIiSSVNTE1paWpTPu7KyskkNAj6fL6QRwW63p+fnW5QldMuRyWSasuXI4/HM+g3Q1NQEs9k86XVerxcul2vOcSaFfh+w65cAgCEpE82jt+IafbnKQRERRZ/b7VY7hKhoaGhAW1sbqqqqIIoibDabMjVN4KutrQ2dnZ2wWq0QRTHt5uyLlYROjrZs2TIpKw5wOByor68PqRNFccokx+FwwGAwhE2o3G73nLrnkspLzcCwPA2BfWwT+rIrsGXDCpWDIiKKPpvNNvNBSSTwuTZdg0BdXR0MBkNaLYMVSwndrabT6bBt2zZYLBbY7Xal3uFwQBCESeulmc1muFyuSWuuud1u2Gw2mM1mNDc3K/WBLruWlha0tbXF9odR01AP8MLPAQCjkga/GHs3brxoERYV8xF+Iko9kUwOnCwCrWCR9JQIgpD6/9GPk4ROjgCguroaOp0OFosFer1eSWjCzXhtMpnQ2to6abmQzZs3T9uqlPJvpl2/AgZFAMBf/NfimLQQWxYm+VN3RERhOBwOtUOIqsDnlsk08xJP7FKLnoRPjgA5Y44ka25oaEBDQ8Ok+s7OzliElRyG+4HnfwIAkJCBn42+BwBQuapUzaiIiKLO6/WitrZ22vU0k02gISDcZ6DL5QqpjySBosgkRXJE87Drl0DfWQDAnqJN8AwuAwAs1XFxSyJKHYFJfcvKytDa2gqz2azss1qtytQwZrMZXq8XW7ZsgdVqVYZaBAY4i6Ko9DbodLqQIRdNTU2w2Wzw+XxTPhXW1NSkjPvxeDzQ6/XTLlE1k0DL0blPZrvd7kndh+cONaG5Y3KUyoZ6gH//7/hGBv6Y/wFlV25WQo/FJyKalbq6OtTV1aG+vh5erzdknGqAIAhoa2uDyWSCz+dDc3MzGhoa4HK5YLFY4PV6lWMCSVSwhoYGVFdXQ6/Xh42hsrISjY2NIUmK2WyGx+OZdpmqqQTGG4WbssZisaTcwPNEwuQolb3UDPR3AACki/8Df9lTAsCPpSW5WMzB2ERJ590/fhZne4ZmPjBJLCjKwaN3XRf36xoMBjgcDjQ2NgKQu6w6OztDnvTasGFD2IHdU41RbWpqAjC59cZqtUKv16O+vn7W41sDrUZer1fpMgt+gjvlx8uqiMlRqhrsAv79I7mcocHgtV/GUKv8B7WqvIALXBIlobM9QzjVPah2GCnB5/OFtMjM9xF4i8UStnVIEATodDq4XK5Zd68Fxhud24XX1NSEXbt2zStemh6To1T17/uVJ9RwaQ16CtYAkJOjwlz+2omS0YKinJkPSiJq/jzRbHUJtOR4PJ4pn5bzeDyzPu9U8xsZjUbOZxRj/JRMRd0ngOd/Jpc1WcDbvoLuwVFldxGTI6KkpEYXVKqK5mPvgeQo3AoMwNwGSk833sjn83GJkBjjqNxU9K+twOiAXN5YC5SuhvvIxHQGxblZKgVGRBR/sZ77KNAKNdVaoHMRaDWqqamZtM9oNHK8UYwxOUo1Z18Hdj8gl3OKgeu/jK3/2I8Gx8vKIanWNE9EFMzn84VsR3PG7HAJUGBc0XTjgGabOE03vxHFHpOjVOO6F5D8cvnaz2MwW4dtT0/8w3D9ugrcedUqlYIjIoqt4JUU5kOn04U9z1QrLQTPmXQut9uN1tbWWV1/qvmNKD6YHKWSIy8Ar/9NLhctAa76NMT+Efgluer6dRX43cc2oiSP3WpElJqMRiO8Xq+S2Ljd7kkJhiiKk1qXzrVly5aQ85z7unNbo+rq6mA0GqdcEH02LUBMjNTHkbmpQpKAJ74xsf22RiA7H50d3UrV0pI8PsJPRCnNYDDAbrfDYrGgsrISAJRH6L1eLywWC1wuF0RRhNlshiAIYR/B1+l0cDqdqK2txYYNG5SnwwITTVosFjidzpDJJu12O5qbm1FfXw+9Xg9BEODz+cIuaxWOxWIJaWUKnt/IarUyWYojJkep4uUW4NhLcrnifODyOwAAnf3DyiG6ArYYEVHqq66uDvuEmCAIYWfOnspU63pKkjTla+azVMhcZtGm2GC3WioY7AptNbrpfwCtnPeK/SNKdWl+drwjIyIiSjpMjlLBv74D9J2RyxfcCqyb+J9OcMtRaT5bjoiIiGbC5CjZnX4VeHF88cHMPODmrSG7j/j6lXJFIR/hJyIimgmTo2QmScDfvgxIY/L29V8CdCtDDtl1cOKJjMtW6OIYHBERUXJicpTMXt4OHHlOLpcJwDV3heweHfNj3/EuAIBQUcCWIyIioggwOUpWAyLgDBqE/c4mICs35JDeoVGMjMlPVSwrzYtjcERERMmLyVGyeuLrQO9puXzBrcA606RDDpzqUcrLS/PjFRkREVFSY3KUjDxPArt/L5ezi4B3hp8bY89RUSlfwfFGREREEWFylGwGu4G/fn5i+x33ASXLwx6654iolC9fqYttXERERCmCyVGy+YcF6Doil1dfDxg+GvawnsERPPPmWQBAUU4m9AsK4xQgERFRcmNylExefQTY+6Bczi4CbvspoAn/K3x493H0DcuP+N962VJoNVxTjYiIKBJMjpJF9wngsS9MbN/yPaB0VdhDJUnCb587pGx/+OrwxxEREdFkTI6SwdgI4PgYMNApb1/0PuDSmikP3/nGWXjO9gEANq4uw/olxfGIkoiIKCUwOUoGrm8BR56Xy8XLgVt+AGSE7yaTJAk/cL6hbH/02tWxj4+IiCiFMDlKdK/9BXj+J3JZkwVs+R2QXxb2UEmS8POdHrx8TJ4Ve/2SYtx80eJ4RUpERJQSMtUOgKZx9nXgkc9MbN+8FVheGfbQ0TE/7na8jId3H1fqvmQ6DxoOxCYiIpoVthwlqp7TwB+qgeHxWa4vrgY2fGLKw7/+yCshidFdN67F5vULYx0lERFRymFylIiG+4AHtwDi+HxGiy8B3n3/lOOMdh3y4U+7jgIAsrQZ+PkdBnzpHecjY4rjiYgofiwWC/R6PUpLS+F2u9UOZ9aiFX9TUxMqKytRWlqK0tJS6PV6mEymkK/g/aWlpXC5XFH8SSLH5CjR+McAx8eBk3vk7eLlwAftQM7Ukzj+37MHlfI3b70Q77xkSYyDJCKiSFmtVtjtdoiiGHa/Xq9HfX39vK4Ry6Rrpvgj1dDQgLa2NlRVVUEURdhsNjidzpCvtrY2dHZ2wmq1QhRFlJWFH2Mba0yOEokkAX//MvDGP+TtnGLgDjtQHD7ZOdMziPsefQ3/eOWUUvcfleGXEiEiIvUIgjDtfp1ON6/z22y2eb1+JjPFPxuB1iCj0TjlMXV1dTAYDPO+L3PFAdmJQpKAx78GtP6fvK3JBGp+Dyy6MOzh3YMjeNf9z6C9d1ipu3R5CfKz+SslIko0033IezyeeZ/f6/XO+xzTiVaSEmjhmi4xChAEIapJ2WzwkzQRSBKw4z7ghZ+OV2QAt/0MEN425UuefbM9JDH6+HVr8Jm3r41tnERElHAcDofaIUQs0GpkMplmPFatLjWA3WqJwecFnv/pxPZ7fgRcNvUM2ADw5ulepbz19kvwjVsvRFlBdqwiJCKiBOT1elFbW6t2GBFzOp0AwrccnTv4OpIEKlbYcpQIyvXAB/4I/OkO4Kb/AgwfnvElPYMjSnlVeX4soyMiSnherxdmsxlerxdVVVWw2+1obm4GAHR0dEAURVgslpBumuDXbNmyBVarVXlNYIBwsKamJqV7yePxQK/Xo66ublIsLpcLTqcTer1eqduyZUvYuE0mE7xeL3Q6Hdra2ibtdzgc2LVrF8rLy9HR0RFyzebmZjidTpSVlaG1tRVms1l5ndVqndQlFYv4ZyuQABkMhpB6t9s9qWuwuro6KtecCyZHiWLtZuBzbqB4aUSH7z/VrZTXVBTEKioiSiS2TUDvGbWjiJ7ChUD9zqicShAEtLW1wWQywefzYfv27WhoaFD2u91uVFZWYtu2bcqH7rmvaW5uRkNDA1wuFywWC7xer5JgVFZWorGxMeQD22w2w+PxwGq1KnUWi0V5EisgkJiF43Q6UV9fj9bW1kn7AjHY7fZJ57Jarairq0NdXR3q6+snHXeuWMU/G4HxRucmRoHrxnpQ+WwwOUokESZGw6N+7DokL0K7tCQXi4tzYxkVESWK3jNAzwm1o0hoBoMBzc3Nk1pEDAYDGhsbUVtbC6PRGDLA2GAwwOFwoLGxEYDc5dPZ2akc09TUBGByS4bValUewxcEAS6XC83Nzejs7Aw5TqfTob6+XmmVOpder5+UHLlcLjQ1NU06l9frhcPhUK4ZiVjHH6lAq5HX61W6zHw+n9JipNbg63CYHCWhFw92YHjUDwCoXF3GyR6J0kVhis16H6OfZ6oP2bq6OlgsFqWFKJjP5wtp0QhOngItNeGuo9Pp4HK5lHNP9RTWbD/4LRYLqqurJz0l5vP54PP5Zn2ueMcfTqCb0m63h1ynqakJu3btmvf5o4nJUZIZHvXjm395VdmuWlWqYjREFFdR6oJKVzqdDjqdLuwH8VQf/oFWDY/HM+VTYYFH8d1uN2pqpn+YJlJutztsohJo1YqUWvGHM9X8Rue25CUCJkdJ5q97T+Bgex8A4LIVOnzwypUqR0RElDwEQQg7J9BUj40HjjWbzWGTlUBXVeC4aHzIB85VXl4etXPFM/5wphtv5PP5Ipr3KJ74KH+S+fu+k0r567esR5aWv0IiokgFD7KORODYmZbOiPS42Vyzo6NjzucItBKpEX84gVajcC1TRqMxocYbAUyOkspLB3146nX5SZWCbC0qV7JLjYgoUqIoQhRFbNiwIeLXBMblTDcmJpBQCIIQldmuA+eabtbrc5OYc8chBQ9yViP+c003v1EiYnKURH60401Iklz+yDWrodFwIDYR0bmmav3YunUrdDrdpMHYMwme/+hcbrdbedLMarVi+/btYY8L96j+TNd0OBxhfxav1xsyYaJer5+2xUeN+M811fxGiYrJUZIY80s4EDS30RdN56kYDRFRYjt38LHb7UZzczN27Ngx6VhRFKd9Aqyurg5GoxH19fWTXudyuZTWkOrqamzZsmXSnECiKCpzEE11nXOTm+rqatTV1YVM7Bj8swU/lm80GuH1epVzuN3ukCQkHvFPJ9kSIwDIkKRAWwRFIjCRWFtbW1x/0X9uO4Yv2fcCADauLsP2T14dt2sTUWwNDg7i4MGDWLNmDXJzOW/ZfFgsFrhcLuzYsQPbt29HWVkZvF6vMtlh8IBjr9erHC+KIqqrqyEIQtjH3gF5Ruq2tjbo9XoIggCfzxd2hunArNbnzjBdWloKnU6HLVu2wGazQRRF1NbWKtc3Go2wWq0hny0Oh0OZrXqmazqdTlRWVgJA2GOiHf9MLBaL0jIliiJ0Oh2qqqoAYNLPORez/buZzec3k6NZUiM5GhwZw+bv78RxcQAA8GDtlbhGXxGXaxNR7DE5ip5AshNuKQ5KLbFMjtitlgQeeOGwkhi97fwFTIyIiIhiiMlREnjywMRaSnffdL6KkRAREaU+JkcJbnTMD8/ZXgCAJgNYv7hY5YiIiBJXrObpofSSFDNku1wuZUBa4I0/20cxo3meeJEkCfc99hpOdw8BAK7RV/DxfSKiMM4dXG02m1FfX5808+pQYkn45MjhcKClpUV5jBCQkxyTyaRMKhXP88TTI3uO43fPHwYgtxp9bvM6lSMiIkpMgiCE/PtONB8J3a0WeMxx27ZtIfVGoxE+n2/KSa1idZ54kCQJ7iOduNu+F//Zslep33r7Jdi4JvzaP0RERBQ9CZ0cbd++XZn6/Fw1NTURzbMQzfPEmiRJ+Mqf9+H2nz0He9sxpX7j6jJsqVqhYmRERETpI6GTI7vdPuVKyYIgwO12RzT4LlrnibUHXjyCltajynZRTiY+dNUqbPtwFTIyONaIiIgoHhI6OWptbZ1ypd5A/XQL80X7PLH01Otn8K2/vqpsf/2W9Xjxa5vx7fdejJL8LBUjIyIiSi8JnRwFphufTiRJTbTOEyuH2vvwmT+4MeaXJyv/+HVr8InrBeRnJ/x4eSKKIi5YQBS5WP69JHRyNJ1AsjOXRfBmc56hoSF0d3crX729vfO6Xjgry/LxoatWAQDedclifO1d66N+DSJKXBqN/E/x2NiYypEQJY/A30vg7yea2DQxg61bt+Lee++N6TU0mgw0vms9LlleAuP6RZzLiCjNZGVlISsrC729vSgsLFQ7HKKk0NPTo/ztRFvSthwFBlBPNdA6WudpbGxEV1eX8rVz5855XW86t166FLlZ2pidn4gSU0ZGBoqKitDV1YWBgQG1wyFKeAMDA+ju7kZRUVFMHlhiy9EMcnJykJOTo2zzf3VEFAsVFRUYGBjAkSNHUFxcjKKiImi1Wj6pSjROkiSMjY2hp6cH3d3dyMnJQUVFbBZiT+jkSBCEKQdKB8YITfUUWizOQ0QUK1qtFitWrEB7ezt6enoSYnoRokSUlZUFnU6HiooKaLWx6W1J6OTIYDBM+Q9EINkxGAxxOw8RUSxptVosWrQICxcuxMjICPx+v9ohESUUjUaDrKysmLeoJnRyZDKZYLVaw+7zeDwRLygYrfMQEcVDRkYGsrOz1Q6DKG0l9IDsLVu2wOfzhe0SczgcqK+vD6kTRREul2ve5yEiIqL0ldDJkU6nw7Zt22CxWELqHQ4HBEFAdXV1SL3ZbIbJZJq0kOxsz0NERETpK6G71QCguroaOp0OFosFer1eGTvkdDonHWsymdDa2oqqqqp5nYeIiIjSV4bE+epnxe12o7KyEm1tbRzETURElCRm8/md0N1qRERERPHG5IiIiIgoCJMjIiIioiBMjoiIiIiCJPzTaokmsCjk/v37VY6EiIiIIhX43I5kcWcmR7N06NAhAMCdd96pbiBEREQ0a4cOHcK111477TF8lH+W2tvb8fjjj2P16tXIy8tTO5yU09vbi02bNmHnzp0oLCxUO5yUw/sbW7y/scX7G1upfn8HBgZw6NAh3HTTTaioqJj2WCZHlFC6u7tRUlKCrq4uFBcXqx1OyuH9jS3e39ji/Y0t3t8JHJBNREREFITJEREREVEQJkeUUHJycnDPPfcgJydH7VBSEu9vbPH+xhbvb2zx/k7gmCMiIiKiIGw5IiIiIgrC5IiIiIgoCJMjIiIioiBMjoiIiIiCcPkQihqXywWn0wm9Xg9RFAEADQ0NMTuP2WxGWVkZ6uvrYTAYIIoiWltbYbPZ0NjYCIPBMJ8fJ+FE6/4CgCiKsFgs0Ol0sFqtcblmoov3/U239y8QvXvc3NwMj8cDt9sNn88Ho9E45X3mezh29zel38MSURTY7Xapuro6pM7pdEpGozFm5zEajRKAkC+dTic5nc7Z/wAJLlr3t6GhQaqurpasVqskCIJUV1cX82smAzXubzq9fyUpuvfY4/Eo252dnZLRaJR0Op3U2dkZk2smAzXubyq/h5kc0bx1dnaG/cORJEkyGAySzWaLyXkaGhokp9MpWa1WyWq1Sna7fS7hJ7xo3d9wr53qwztW10xEatxfSUqf968kRe8e2+12qa2tLez5AYQkAnwPy2J1fyUptd/DHHNE87Z9+3YIggCdTjdpX01NDWw2W8zOYzQa0dDQgIaGBlRXV8829KQQrfub6NdUi5o/azq8f4Ho3eNdu3aF7arR6XSoq6uDy+VSupP4HpbF6v4GpOp7mMkRzZvdbkdZWVnYfYIgwO12T/qDiuV5Uo0a9yWdfhfp9LOqJVr3uLm5GSaTKey+yspKAEBra2tUr5kM1Li/qY7JEc1ba2srBEEIuy9Q7/V643aeVKPGfUmn30U6/axqidY9rqqqmnJf4MM/kCSk0+9Vjfub6vi0Gs2bKIphm3ODeb3eGZ9cmMt5vF4vXC6Xsu3xeNDY2DjjeZJJtO5vol9TLWr+rOnw/gWid4+dTueU+zweDwAo5+B7OFS072/weVPxPczkiGIq8Afi8/mifh6v1wu32426ujqlzu12o7KyEm1tbUn/xxmJaN3fRL+mWmL5s/L9K4vWPW5ubg65l/G4ZjKI5f1N5fcwu9Uoadnt9kkDAA0GAwwGA2pra1WKiigyfP9Gj8VigSAI087ZRXM31f1N5fcwkyOKqWj1U8/mPCaTCQ6HY17XSxZqjANIp7EHavys6fT+BeZ/j91uN5qbm+F0OiNuqeB7OHJzub+p8B5mckQpJ/CPgNvtVjkSotnj+3d2zGYzduzYMeWAZJqfudzfVHgPMzmieRMEYconIQL93JH8Yc3mPPX19bBYLGGPTbXxBNG6v4l+TbWo8bOm0/sXiN09NplMsNlsYQca8z0si9X9TfX3MJMjmrfAmjrhBP5gI3kiZDbn2b59+5T/GATqp3ssNZlE6/4m+jXVosbPmk7vXyA29zjw4Ww0GuN2zUSlxv1N9fcwkyOaN5PJNOUficfjmfKPaz7nqaurg91uD3us0+mccrbYZBSt+5vo11SLGj9rOr1/gejf46amJpjN5kmvC36snO9hWazub8q/h9Vev4SSX2Bdn+DFCgMEQZi03k5nZ2fYhQlnc56Z1gBKpTV+onV/zxXJ2mqRXjOZqXF/0+n9K0nRvcd2u33afYFr8D0si9X9TfX3MJMjiopwK0Lb7fawK0IHVnIOtxjibM5TV1c36Y9zpsU+k1W07m8wQRAmnXOu10x2atzfdHr/SlJ07nFbW5tkNBolm80W8hVY+NRgMMz5mslOjfubyu/hDEmSJPXarSiVuFwuOJ1O6PV6pf+7oaFh0nFNTU3YunUrduzYEbYfPNLzBM7V0dEBURTh8/lQU1OTUosfBovG/W1qasKuXbuUydsAeeFInU4X9t7N5neR7NS4v+n0/gXmf49LS0unXSNMEARlJufZXjMVqHF/U/U9zOSIiIiIKAgHZBMREREFYXJEREREFITJEREREVEQJkdEREREQZgcEREREQVhckREREQUhMkRERERURAmR0RERERBmBwRUVpzuVzQ6/WwWCxqh0JECSJT7QCIiNRkNBphs9lgMpkAAFarVeWIiEhtXD6EiAiAXq+Hz+dDZ2en2qEQkcrYrUZEBKC+vh6iKMLhcKgdChGpjMkRERGAuro6AEBLS4vKkRCR2titRkQ0zmQyweVyobOzEzqdTu1wiEglbDkiIhpnNpsBANu3b1c5EiJSE1uOiIiCZGRkwGAwoK2tTe1QiEglbDkiIgpSXV0Nt9sNr9erdihEpBImR0RE40RRVJIiPrVGlL7YrUZEBDkx2rx5M+x2OyorK1FWVgaPx6N2WESkArYcEVHa83q9qKysxLZt2yAIArZs2QKv1wu32612aESkAiZHRJTWAomRzWaDwWAAIE8ICQA2m03N0IhIJexWI6K0FUiMrFarMglkAJcTIUpfbDkiorQUSIy2bNkyKTECJpYTcblcKkRHRGpickREaSeQGFVVVU3ZdVZdXQ2AXWtE6YjJERGlHZvNBkEQ4HQ6pzxGEATU1dXB4XBwziOiNMMxR0RERERB2HJEREREFITJEREREVEQJkdEREREQZgcEREREQVhckREREQUhMkRERERURAmR0RERERBmBwRERERBWFyRERERBSEyRERERFRECZHREREREGYHBEREREFYXJEREREFITJEREREVEQJkdEREREQf4/zqm50Lw/JSoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ALPHA=0.6\n",
    "BETA=0.4\n",
    "eval_df_single_point, eval_array_single_point = generate_eval_data(alpha=ALPHA,beta=BETA, K=300)\n",
    "eval_tensor_single_point = torch.Tensor(eval_array_single_point)\n",
    "CDF_hat = untrained_SIR_model(eval_tensor_single_point).detach().numpy()\n",
    "lambda_ = eval_df_single_point['li']\n",
    "true_CDF = eval_df_single_point['true_CDF']\n",
    "\n",
    "# xmin, xmax = lambda_.min(), lambda_.max()\n",
    "# ymin, ymax = true_CDF.min(), true_CDF.max()\n",
    "plt.text(0.1, 0.25, r'$\\alpha = %.2f, \\beta = %.2f$' % (ALPHA,BETA))\n",
    "plt.plot(lambda_, true_CDF, label=r'true $F$', linewidth=2)\n",
    "plt.plot(lambda_, CDF_hat, label = r'predicted $F$',linewidth=2)\n",
    "plt.ylabel(r'$F$')\n",
    "plt.xlabel(r'$\\lambda$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb361ee-db8b-448f-bd3f-567c1a59f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fcd4c3-7ba4-4a04-ac47-5250e6281419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
