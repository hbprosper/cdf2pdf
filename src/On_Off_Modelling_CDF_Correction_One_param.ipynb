{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17b96dca-a206-4861-90bd-15f28c2900cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; import pandas as pd\n",
    "import scipy as sp; import scipy.stats as st\n",
    "import torch; import torch.nn as nn\n",
    "#use numba's just-in-time compiler to speed things up\n",
    "from numba import njit\n",
    "from sklearn.preprocessing import StandardScaler; from sklearn.model_selection import train_test_split\n",
    "import matplotlib as mp; import matplotlib.pyplot as plt; \n",
    "#reset matplotlib stle/parameters\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "plt.style.use('seaborn-deep')\n",
    "mp.rcParams['agg.path.chunksize'] = 10000\n",
    "font_legend = 15; font_axes=15\n",
    "# %matplotlib inline\n",
    "from joblib import  Memory\n",
    "\n",
    "import copy; import sys; import os\n",
    "from IPython.display import Image, display\n",
    "from importlib import import_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34afd9c1-8795-4332-b495-8e6308b069ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTSIZE=18\n",
    "font = {'family': 'serif', 'weight':'normal', 'size':FONTSIZE}\n",
    "mp.rc('font', **font)\n",
    "mp.rc('text',usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01297c5d-a1ef-45a1-852e-21bc72bdaa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug(func):\n",
    "    \"\"\"Print the function signature and return value\"\"\"\n",
    "    import functools\n",
    "\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_debug(*args, **kwargs):\n",
    "        args_repr = [repr(a) for a in args]\n",
    "        kwargs_repr = [f\"{k}={v!r}\" for k, v in kwargs.items()]\n",
    "        signature = \", \".join(args_repr + kwargs_repr)\n",
    "        print(f\"Calling {func.__name__}({signature})\")\n",
    "        values = func(*args, **kwargs)\n",
    "        print(f\"{func.__name__!r} returned {values!r}\")\n",
    "        return values\n",
    "\n",
    "    return wrapper_debug\n",
    "\n",
    "def theta_hat_func(n,m, MLE):\n",
    "       #n,m are integer arrays\n",
    "    if MLE==True:\n",
    "        theta_hat = n-m\n",
    "    else:\n",
    "        # non-MLE\n",
    "        # theta_hat = n-m\n",
    "        # theta_hat = (theta_hat) * (theta_hat > 0)\n",
    "        theta_hat = np.where(n>m, n-m, 0)\n",
    "         \n",
    "    return theta_hat\n",
    "\n",
    "\n",
    "def L_prof_global(n,m, MLE):\n",
    "    #n,m integer arrays\n",
    "    # nu_hat = m, if theta_hat = theta_hat_MLE\n",
    "    # nu_hat  =  (m+n)/2 if theta_hat = n-m\n",
    "    # nu_hat = 0  if theta_hat != n-m\n",
    "    theta_hat=theta_hat_func(n,m,MLE)\n",
    "    # print('n-m ',  n-m)\n",
    "    if MLE==True:\n",
    "        # i.e. if theta_hat = n-m\n",
    "        # assert theta_hat==n-m\n",
    "        nu_hat = m\n",
    "    else:\n",
    "        nu_hat = np.where(theta_hat ==0, (m+n)/2, m)\n",
    "        # if theta_hat==0:\n",
    "        #     nu_hat =(m+n)/2\n",
    "        # else:\n",
    "        #     _hat = m\n",
    "        # # if theta_hat== n-m:\n",
    "        # #     nu_hat = (m+n)/2\n",
    "        # # else:\n",
    "        # #     nu_hat = 0\n",
    "        # # nu_hat = np.where(theta_hat==n-m,\n",
    "        # #                   (m+n)/2, \n",
    "        # #                   0)\n",
    "    p1=st.poisson.pmf(n, theta_hat+nu_hat)\n",
    "    p2 = st.poisson.pmf(m, nu_hat)\n",
    "    return p1*p2\n",
    "\n",
    "def L_theta_nu(n,m,theta,nu):\n",
    "    p1 = st.poisson.pmf(n, theta+nu)\n",
    "    p2 = st.poisson.pmf(m, nu)\n",
    "    return p1*p2\n",
    "def lambda_test_2d(n,m, theta, nu, MLE):\n",
    "    Ln= L_theta_nu(n,m,theta,nu)\n",
    "    \n",
    "    Ld= L_prof_global(n,m, MLE)\n",
    "    eps=1e-20\n",
    "    Ld=Ld+eps\n",
    "    lambda_  = -2*np.log(Ln/Ld)\n",
    "    return np.array(lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05762bc0-00a9-4a95-ba91-13b41e66ef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiLURegressionModel(nn.Module):\n",
    "    #inherit from the super class\n",
    "    def __init__(self, nfeatures, ntargets, nlayers, hidden_size, dropout):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(nlayers):\n",
    "            if len(layers) ==0:\n",
    "                #inital layer has to have size of input features as its input layer\n",
    "                #its output layer can have any size but it must match the size of the input layer of the next linear layer\n",
    "                #here we choose its output layer as the hidden size (fully connected)\n",
    "                layers.append(nn.Linear(nfeatures, hidden_size))\n",
    "                #batch normalization\n",
    "                # layers.append(nn.BatchNorm1d(hidden_size))\n",
    "                #Dropout seems to worsen model performance\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "                #ReLU activation \n",
    "                layers.append(nn.SiLU())\n",
    "            else:\n",
    "                #if this is not the first layer (we dont have layers)\n",
    "                layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "                # layers.append(nn.BatchNorm1d(hidden_size))\n",
    "                #Dropout seems to worsen model performance\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "                layers.append(nn.SiLU())\n",
    "                #output layer:\n",
    "        layers.append(nn.Linear(hidden_size, ntargets)) \n",
    "\n",
    "        # ONLY IF ITS A CLASSIFICATION, ADD SIGMOID\n",
    "        layers.append(nn.Sigmoid())\n",
    "            #we have defined sequential model using the layers in oulist \n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cf74a41-e2f8-480a-bc6c-9b066cc34569",
   "metadata": {},
   "outputs": [],
   "source": [
    "@debug\n",
    "def load_untrained_model(PARAMS):\n",
    "    \"\"\"Load an untrained model (with weights initiatted) according to model paramateters in the \n",
    "    PARAMS dictionary\n",
    "\n",
    "    Args:\n",
    "        PARAMS (dict): dictionary of model/training parameters: i.e. hyperparameters and training parameters.\n",
    "\n",
    "    Returns:\n",
    "        utils.RegularizedRegressionModel object\n",
    "    \"\"\"\n",
    "    model = SiLURegressionModel(\n",
    "        nfeatures=PARAMS['NFEATURES'],\n",
    "        ntargets=1,\n",
    "        nlayers=PARAMS[\"n_layers\"],\n",
    "        hidden_size=PARAMS[\"hidden_size\"],\n",
    "        dropout=PARAMS[\"dropout\"],\n",
    "        # activation=PARAMS[\"activation\"]\n",
    "    )\n",
    "    # model.apply(initialize_weights)\n",
    "    print('INITIATED UNTRAINED MODEL:',\n",
    "          # model\n",
    "         )\n",
    "    # print(model)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98f0136c-e114-4cbb-8497-2977ca2bbc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS_lambdaD_nonMLE_SILU = {\n",
    "\"n_layers\": int(12),\n",
    "\"hidden_size\": int(12),\n",
    "\"dropout\": float(0.13),\n",
    "\"NFEATURES\":int(3),\n",
    "\"activation\": \"SiLU\",\n",
    "'optimizer_name':'NAdam',\n",
    "    # 'optimizer_name':'RMSprop',\n",
    "'starting_learning_rate':float(0.0006),\n",
    "'momentum':float(0.9),\n",
    "'batch_size':int(256*2),\n",
    "'n_iterations': int(1e5),\n",
    "'traces_step':int(100),\n",
    "'L2':float(0.1),\n",
    "'MLE':False,\n",
    "'with_lambda_D':True,\n",
    "'pth_string':'FEB_20_model_lambda_D_nonMLE_SILU.pth'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee9925c5-dd21-4021-b491-9e4fdc4412ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling load_untrained_model({'n_layers': 12, 'hidden_size': 12, 'dropout': 0.13, 'NFEATURES': 3, 'activation': 'SiLU', 'optimizer_name': 'NAdam', 'starting_learning_rate': 0.0006, 'momentum': 0.9, 'batch_size': 512, 'n_iterations': 100000, 'traces_step': 100, 'L2': 0.1, 'MLE': False, 'with_lambda_D': True, 'pth_string': 'FEB_20_model_lambda_D_nonMLE_SILU.pth'})\n",
      "INITIATED UNTRAINED MODEL:\n",
      "'load_untrained_model' returned SiLURegressionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=12, bias=True)\n",
      "    (1): Dropout(p=0.13, inplace=False)\n",
      "    (2): SiLU()\n",
      "    (3): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (4): Dropout(p=0.13, inplace=False)\n",
      "    (5): SiLU()\n",
      "    (6): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (7): Dropout(p=0.13, inplace=False)\n",
      "    (8): SiLU()\n",
      "    (9): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (10): Dropout(p=0.13, inplace=False)\n",
      "    (11): SiLU()\n",
      "    (12): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (13): Dropout(p=0.13, inplace=False)\n",
      "    (14): SiLU()\n",
      "    (15): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (16): Dropout(p=0.13, inplace=False)\n",
      "    (17): SiLU()\n",
      "    (18): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (19): Dropout(p=0.13, inplace=False)\n",
      "    (20): SiLU()\n",
      "    (21): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (22): Dropout(p=0.13, inplace=False)\n",
      "    (23): SiLU()\n",
      "    (24): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (25): Dropout(p=0.13, inplace=False)\n",
      "    (26): SiLU()\n",
      "    (27): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (28): Dropout(p=0.13, inplace=False)\n",
      "    (29): SiLU()\n",
      "    (30): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (31): Dropout(p=0.13, inplace=False)\n",
      "    (32): SiLU()\n",
      "    (33): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (34): Dropout(p=0.13, inplace=False)\n",
      "    (35): SiLU()\n",
      "    (36): Linear(in_features=12, out_features=1, bias=True)\n",
      "    (37): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "untrained_SiLU_model_nonMLE = load_untrained_model(PARAMS_lambdaD_nonMLE_SILU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc9b269e-c891-400e-bc53-51234006c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, PARAMS, pth_string):\n",
    "    models_path = os.path.join(os.getcwd(), '../models')\n",
    "    PATH=os.path.join(models_path, pth_string)\n",
    "    model = SiLURegressionModel(\n",
    "        nfeatures=PARAMS['NFEATURES'],\n",
    "        ntargets=1,\n",
    "        nlayers=PARAMS[\"n_layers\"],\n",
    "        hidden_size=PARAMS[\"hidden_size\"],\n",
    "        dropout=PARAMS[\"dropout\"]\n",
    "    )\n",
    "    checkpoint = torch.load(PATH)\n",
    "    print('INITIATED MODEL:',  model)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f'loading model with th string : {pth_string}\\n')    \n",
    "    print(model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a6468a1-d653-4635-b434-646bab9f4703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIATED MODEL: SiLURegressionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=12, bias=True)\n",
      "    (1): Dropout(p=0.13, inplace=False)\n",
      "    (2): SiLU()\n",
      "    (3): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (4): Dropout(p=0.13, inplace=False)\n",
      "    (5): SiLU()\n",
      "    (6): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (7): Dropout(p=0.13, inplace=False)\n",
      "    (8): SiLU()\n",
      "    (9): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (10): Dropout(p=0.13, inplace=False)\n",
      "    (11): SiLU()\n",
      "    (12): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (13): Dropout(p=0.13, inplace=False)\n",
      "    (14): SiLU()\n",
      "    (15): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (16): Dropout(p=0.13, inplace=False)\n",
      "    (17): SiLU()\n",
      "    (18): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (19): Dropout(p=0.13, inplace=False)\n",
      "    (20): SiLU()\n",
      "    (21): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (22): Dropout(p=0.13, inplace=False)\n",
      "    (23): SiLU()\n",
      "    (24): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (25): Dropout(p=0.13, inplace=False)\n",
      "    (26): SiLU()\n",
      "    (27): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (28): Dropout(p=0.13, inplace=False)\n",
      "    (29): SiLU()\n",
      "    (30): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (31): Dropout(p=0.13, inplace=False)\n",
      "    (32): SiLU()\n",
      "    (33): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (34): Dropout(p=0.13, inplace=False)\n",
      "    (35): SiLU()\n",
      "    (36): Linear(in_features=12, out_features=1, bias=True)\n",
      "    (37): Sigmoid()\n",
      "  )\n",
      ")\n",
      "loading model with th string : FEB_20_model_lambda_D_nonMLE_SILU.pth\n",
      "\n",
      "SiLURegressionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=12, bias=True)\n",
      "    (1): Dropout(p=0.13, inplace=False)\n",
      "    (2): SiLU()\n",
      "    (3): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (4): Dropout(p=0.13, inplace=False)\n",
      "    (5): SiLU()\n",
      "    (6): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (7): Dropout(p=0.13, inplace=False)\n",
      "    (8): SiLU()\n",
      "    (9): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (10): Dropout(p=0.13, inplace=False)\n",
      "    (11): SiLU()\n",
      "    (12): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (13): Dropout(p=0.13, inplace=False)\n",
      "    (14): SiLU()\n",
      "    (15): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (16): Dropout(p=0.13, inplace=False)\n",
      "    (17): SiLU()\n",
      "    (18): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (19): Dropout(p=0.13, inplace=False)\n",
      "    (20): SiLU()\n",
      "    (21): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (22): Dropout(p=0.13, inplace=False)\n",
      "    (23): SiLU()\n",
      "    (24): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (25): Dropout(p=0.13, inplace=False)\n",
      "    (26): SiLU()\n",
      "    (27): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (28): Dropout(p=0.13, inplace=False)\n",
      "    (29): SiLU()\n",
      "    (30): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (31): Dropout(p=0.13, inplace=False)\n",
      "    (32): SiLU()\n",
      "    (33): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (34): Dropout(p=0.13, inplace=False)\n",
      "    (35): SiLU()\n",
      "    (36): Linear(in_features=12, out_features=1, bias=True)\n",
      "    (37): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# untrained_SiLU_model = load_untrained_model(PARAMS_lambdaD_nonMLE_SILU)\n",
    "\n",
    "trained_SiLU_model_nonMLE = load_model(model = untrained_SiLU_model_nonMLE, \n",
    "                                PARAMS=PARAMS_lambdaD_nonMLE_SILU,\n",
    "                   pth_string=PARAMS_lambdaD_nonMLE_SILU[\"pth_string\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b8ddcc5-5a97-4329-91ed-48c550050486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1777"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def number_of_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "number_of_parameters(trained_SiLU_model_nonMLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9368bb4-450d-415d-ac51-af3e190a871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS_lambdaD_MLE_SILU = {\n",
    "\"n_layers\": int(12),\n",
    "\"hidden_size\": int(12),\n",
    "\"dropout\": float(0.13),\n",
    "\"NFEATURES\":int(3),\n",
    "\"activation\": \"SiLU\",\n",
    "'optimizer_name':'NAdam',\n",
    "    # 'optimizer_name':'RMSprop',\n",
    "'starting_learning_rate':float(0.0006),\n",
    "'momentum':float(0.9),\n",
    "'batch_size':int(256*2),\n",
    "'n_iterations': int(6e4),\n",
    "'traces_step':int(100),\n",
    "'L2':float(0.1),\n",
    "'MLE':True,\n",
    "'with_lambda_D':True,\n",
    "'pth_string':'FEB_20_model_lambda_D_MLE_SILU.pth'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "638b8951-7306-4d93-8b08-09b90884bfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling load_untrained_model({'n_layers': 12, 'hidden_size': 12, 'dropout': 0.13, 'NFEATURES': 3, 'activation': 'SiLU', 'optimizer_name': 'NAdam', 'starting_learning_rate': 0.0006, 'momentum': 0.9, 'batch_size': 512, 'n_iterations': 60000, 'traces_step': 100, 'L2': 0.1, 'MLE': True, 'with_lambda_D': True, 'pth_string': 'FEB_20_model_lambda_D_MLE_SILU.pth'})\n",
      "INITIATED UNTRAINED MODEL:\n",
      "'load_untrained_model' returned SiLURegressionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=12, bias=True)\n",
      "    (1): Dropout(p=0.13, inplace=False)\n",
      "    (2): SiLU()\n",
      "    (3): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (4): Dropout(p=0.13, inplace=False)\n",
      "    (5): SiLU()\n",
      "    (6): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (7): Dropout(p=0.13, inplace=False)\n",
      "    (8): SiLU()\n",
      "    (9): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (10): Dropout(p=0.13, inplace=False)\n",
      "    (11): SiLU()\n",
      "    (12): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (13): Dropout(p=0.13, inplace=False)\n",
      "    (14): SiLU()\n",
      "    (15): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (16): Dropout(p=0.13, inplace=False)\n",
      "    (17): SiLU()\n",
      "    (18): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (19): Dropout(p=0.13, inplace=False)\n",
      "    (20): SiLU()\n",
      "    (21): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (22): Dropout(p=0.13, inplace=False)\n",
      "    (23): SiLU()\n",
      "    (24): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (25): Dropout(p=0.13, inplace=False)\n",
      "    (26): SiLU()\n",
      "    (27): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (28): Dropout(p=0.13, inplace=False)\n",
      "    (29): SiLU()\n",
      "    (30): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (31): Dropout(p=0.13, inplace=False)\n",
      "    (32): SiLU()\n",
      "    (33): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (34): Dropout(p=0.13, inplace=False)\n",
      "    (35): SiLU()\n",
      "    (36): Linear(in_features=12, out_features=1, bias=True)\n",
      "    (37): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "untrained_SiLU_model_MLE = load_untrained_model(PARAMS_lambdaD_MLE_SILU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10ba18ea-5403-4855-8436-c55d957819e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIATED MODEL: SiLURegressionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=12, bias=True)\n",
      "    (1): Dropout(p=0.13, inplace=False)\n",
      "    (2): SiLU()\n",
      "    (3): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (4): Dropout(p=0.13, inplace=False)\n",
      "    (5): SiLU()\n",
      "    (6): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (7): Dropout(p=0.13, inplace=False)\n",
      "    (8): SiLU()\n",
      "    (9): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (10): Dropout(p=0.13, inplace=False)\n",
      "    (11): SiLU()\n",
      "    (12): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (13): Dropout(p=0.13, inplace=False)\n",
      "    (14): SiLU()\n",
      "    (15): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (16): Dropout(p=0.13, inplace=False)\n",
      "    (17): SiLU()\n",
      "    (18): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (19): Dropout(p=0.13, inplace=False)\n",
      "    (20): SiLU()\n",
      "    (21): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (22): Dropout(p=0.13, inplace=False)\n",
      "    (23): SiLU()\n",
      "    (24): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (25): Dropout(p=0.13, inplace=False)\n",
      "    (26): SiLU()\n",
      "    (27): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (28): Dropout(p=0.13, inplace=False)\n",
      "    (29): SiLU()\n",
      "    (30): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (31): Dropout(p=0.13, inplace=False)\n",
      "    (32): SiLU()\n",
      "    (33): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (34): Dropout(p=0.13, inplace=False)\n",
      "    (35): SiLU()\n",
      "    (36): Linear(in_features=12, out_features=1, bias=True)\n",
      "    (37): Sigmoid()\n",
      "  )\n",
      ")\n",
      "loading model with th string : FEB_20_model_lambda_D_MLE_SILU.pth\n",
      "\n",
      "SiLURegressionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=12, bias=True)\n",
      "    (1): Dropout(p=0.13, inplace=False)\n",
      "    (2): SiLU()\n",
      "    (3): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (4): Dropout(p=0.13, inplace=False)\n",
      "    (5): SiLU()\n",
      "    (6): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (7): Dropout(p=0.13, inplace=False)\n",
      "    (8): SiLU()\n",
      "    (9): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (10): Dropout(p=0.13, inplace=False)\n",
      "    (11): SiLU()\n",
      "    (12): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (13): Dropout(p=0.13, inplace=False)\n",
      "    (14): SiLU()\n",
      "    (15): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (16): Dropout(p=0.13, inplace=False)\n",
      "    (17): SiLU()\n",
      "    (18): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (19): Dropout(p=0.13, inplace=False)\n",
      "    (20): SiLU()\n",
      "    (21): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (22): Dropout(p=0.13, inplace=False)\n",
      "    (23): SiLU()\n",
      "    (24): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (25): Dropout(p=0.13, inplace=False)\n",
      "    (26): SiLU()\n",
      "    (27): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (28): Dropout(p=0.13, inplace=False)\n",
      "    (29): SiLU()\n",
      "    (30): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (31): Dropout(p=0.13, inplace=False)\n",
      "    (32): SiLU()\n",
      "    (33): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (34): Dropout(p=0.13, inplace=False)\n",
      "    (35): SiLU()\n",
      "    (36): Linear(in_features=12, out_features=1, bias=True)\n",
      "    (37): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# untrained_SiLU_model = load_untrained_model(PARAMS_lambdaD_nonMLE_SILU)\n",
    "\n",
    "trained_SiLU_model_MLE = load_model(model = untrained_SiLU_model_MLE, \n",
    "                                PARAMS=PARAMS_lambdaD_MLE_SILU,\n",
    "                   pth_string=PARAMS_lambdaD_MLE_SILU[\"pth_string\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45353130-c2a7-4664-b2b8-cf1dbeccbf28",
   "metadata": {},
   "source": [
    "# Summary: We have loaded `trained_SiLU_model_nonMLE` and `trained_SiLU_model_MLE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b24bcd04-16f4-4f8c-ad3c-3450b06a6c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainedModel:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def __cdf(self, x):\n",
    "        # convert to a tensor and compute\n",
    " \n",
    "        X = torch.Tensor(x)#.transpose(1, 0)\n",
    "            \n",
    "        X.requires_grad_(True)\n",
    "        \n",
    "        self.model.eval() \n",
    "        \n",
    "        return self.model(X), X \n",
    "        \n",
    "    def cdf(self, x): \n",
    "        F, _ = self.__cdf(x)\n",
    "        \n",
    "        Y = F.view(-1).detach().numpy()\n",
    "        if len(Y) == 1:\n",
    "            Y = Y[0]\n",
    "        return Y\n",
    "\n",
    "        \n",
    "        Y = F.view(-1).detach().numpy()\n",
    "        if len(Y) == 1:\n",
    "            Y = Y[0]\n",
    "        return Y\n",
    "    \n",
    "    def numerical_deriv(self,x):\n",
    "        h=1E-3\n",
    "        F_h = self.cdf(x+h)\n",
    "        F = self.cdf(x)\n",
    "        deriv = (F_h-F)/h\n",
    "        return deriv\n",
    "        \n",
    "\n",
    "    def pdf(self, x):\n",
    "        F, X = self.__cdf(x)\n",
    "\n",
    "        dFdX = torch.autograd.grad(outputs=F, inputs=X, \n",
    "                               grad_outputs=torch.ones_like(F),\n",
    "                               #allow_unused=True, \n",
    "                               #retain_graph=True, \n",
    "                               create_graph=True)[0]\n",
    "    \n",
    "        # Y = dFdX.view(-1).detach().numpy()\n",
    "        Y = dFdX.detach().numpy()\n",
    "        if len(Y) == 1:\n",
    "            Y = Y[0]\n",
    "        return Y.T[-1]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6354043d-851c-4f78-8424-904e1dc1cd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_X(theta, nu, N_points, MLE):\n",
    "    N = st.poisson.rvs(theta+nu, size=N_points)\n",
    "    M = st.poisson.rvs(nu, size=N_points)\n",
    "    lambda_D = lambda_test_2d(N, M, theta, nu, MLE).flatten()\n",
    "    X = np.empty((N_points, 3))\n",
    "    X[:,0] = np.ones_like(theta)*theta\n",
    "    X[:,1] = np.ones_like(nu)*nu\n",
    "    X[:,2]  = lambda_D\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "370fab1a-3c8b-4713-b525-a32b7427c3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta</th>\n",
       "      <th>nu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   theta   nu\n",
       "0   20.0  5.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta, nu = 20., 5.\n",
    "data = pd.DataFrame({'theta':[theta], 'nu':[nu]})\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bddabdbe-3234-472b-baba-dfdd11b8ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmodel = TrainedModel(trained_SiLU_model_nonMLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ce3ae69-49f1-455d-87eb-70a91b24f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(arr):\n",
    "    return [float(int(1000*x))/1000 for x in arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff93361a-3175-4e3a-9e49-943bbceb9d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rowind, row in data.iterrows():\n",
    "    N=1000\n",
    "    X = generate_X(theta=row['theta'], nu=row['nu'], N_points=N, MLE=False)\n",
    "    lambda_ = X[:,2].flatten()\n",
    "    # lambda_ = [float(int(1000*x))/1000 for x in lambda_]\n",
    "    lambda_ = precision(lambda_)\n",
    "    # data.loc[rowind, 'lambda'] = [str(x) for x in lambda_]\n",
    "    data.loc[rowind, 'lambda'] =str(lambda_)\n",
    "    a = tmodel.cdf(X)\n",
    "\n",
    "    p  = np.linspace(0,1,N)\n",
    "    \n",
    "    q = np.quantile(a,p)\n",
    "\n",
    "    q = precision(q)\n",
    "    data.loc[rowind, 'q'] = str(q)\n",
    "    delta_C = p-q\n",
    "    delta_C = precision(delta_C)\n",
    "    data.loc[rowind, 'delta_C'] = str(delta_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "609d542c-ae74-4dbb-ba79-b28bb1ab8ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta</th>\n",
       "      <th>nu</th>\n",
       "      <th>lambda</th>\n",
       "      <th>q</th>\n",
       "      <th>delta_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[0.796, 0.939, 2.271, 0.346, 2.856, 2.734, 1.5...</td>\n",
       "      <td>[0.039, 0.039, 0.039, 0.039, 0.039, 0.039, 0.0...</td>\n",
       "      <td>[-0.039, -0.037, -0.036, -0.035, -0.034, -0.03...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   theta   nu                                             lambda  \\\n",
       "0   20.0  5.0  [0.796, 0.939, 2.271, 0.346, 2.856, 2.734, 1.5...   \n",
       "\n",
       "                                                   q  \\\n",
       "0  [0.039, 0.039, 0.039, 0.039, 0.039, 0.039, 0.0...   \n",
       "\n",
       "                                             delta_C  \n",
       "0  [-0.039, -0.037, -0.036, -0.035, -0.034, -0.03...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3fe726c5-b42b-461d-8a50-d8fed6ffef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_l = []\n",
    "nu_l= []\n",
    "q_l = []\n",
    "delta_C_l = []\n",
    "\n",
    "for row_ind, row in data.iterrows():\n",
    "    q=eval(row['q'])\n",
    "    \n",
    "    theta_r = np.full_like(q, row['theta'])\n",
    "    theta_l.append(theta_r)\n",
    "    \n",
    "    nu_r = np.full_like(q, row['nu'])\n",
    "    nu_l.append(nu_r)\n",
    "    \n",
    "    q_l.append(q)\n",
    "    \n",
    "    delta_C = eval(row['delta_C'])\n",
    "    delta_C_l.append(delta_C)\n",
    "\n",
    "theta_l=np.array(theta_l).flatten()\n",
    "nu_l=np.array(nu_l).flatten()\n",
    "q_l=np.array(q_l).flatten()\n",
    "delta_C_l=np.array(delta_C_l).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f79ccfd9-2a58-4a50-9507-be50542982ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta</th>\n",
       "      <th>nu</th>\n",
       "      <th>q</th>\n",
       "      <th>delta_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   theta   nu      q  delta_C\n",
       "0   20.0  5.0  0.039   -0.039\n",
       "1   20.0  5.0  0.039   -0.037\n",
       "2   20.0  5.0  0.039   -0.036\n",
       "3   20.0  5.0  0.039   -0.035\n",
       "4   20.0  5.0  0.039   -0.034\n",
       "5   20.0  5.0  0.039   -0.033\n",
       "6   20.0  5.0  0.039   -0.032\n",
       "7   20.0  5.0  0.039   -0.031\n",
       "8   20.0  5.0  0.039   -0.030\n",
       "9   20.0  5.0  0.039   -0.029"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_flat=pd.DataFrame({'theta': theta_l,\n",
    "                       'nu': nu_l,\n",
    "                       'q': q_l,\n",
    "                       'delta_C': delta_C_l})\n",
    "data_flat[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc0e9bba-735d-4ee6-be94-66f6bb5a28bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_t_x(df, target, source):\n",
    "    # change from pandas dataframe format to a numpy \n",
    "    # array of the specified types\n",
    "    t = np.array(df[target])\n",
    "    x = np.array(df[source])\n",
    "    return t, x\n",
    "\n",
    "class SiLURegressionModel(nn.Module):\n",
    "    #inherit from the super class\n",
    "    def __init__(self, nfeatures, ntargets, nlayers, hidden_size, dropout):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(nlayers):\n",
    "            if len(layers) ==0:\n",
    "                #inital layer has to have size of input features as its input layer\n",
    "                #its output layer can have any size but it must match the size of the input layer of the next linear layer\n",
    "                #here we choose its output layer as the hidden size (fully connected)\n",
    "                layers.append(nn.Linear(nfeatures, hidden_size))\n",
    "                #batch normalization\n",
    "                # layers.append(nn.BatchNorm1d(hidden_size))\n",
    "                #Dropout seems to worsen model performance\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "                #ReLU activation \n",
    "                layers.append(nn.SiLU())\n",
    "            else:\n",
    "                #if this is not the first layer (we dont have layers)\n",
    "                layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "                # layers.append(nn.BatchNorm1d(hidden_size))\n",
    "                #Dropout seems to worsen model performance\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "                layers.append(nn.SiLU())\n",
    "                #output layer:\n",
    "        layers.append(nn.Linear(hidden_size, ntargets)) \n",
    "\n",
    "        # ONLY IF ITS A CLASSIFICATION, ADD SIGMOID\n",
    "        layers.append(nn.Sigmoid())\n",
    "            #we have defined sequential model using the layers in oulist \n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88682b61-51a8-4256-afd3-740698254695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getwholedata_delta_C():\n",
    "    \"\"\" Get train test split arrays\"\"\"\n",
    "    \n",
    "    data = data_flat\n",
    "        \n",
    "    train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "    #split the train data (0.8 of whole set) again into 0.8*0.8=0.64 of whole set\n",
    "    \n",
    "\n",
    "    train_data = train_data.reset_index(drop=True)\n",
    "    test_data  = test_data.reset_index(drop=True)\n",
    "\n",
    "    target='delta_C'\n",
    "    # source = ['theta','nu','theta_hat','N','M']\n",
    "\n",
    "    source = ['q']\n",
    "\n",
    "    train_t, train_x = split_t_x(train_data, target=target, source=source)\n",
    "    test_t,  test_x  = split_t_x(test_data,  target=target, source=source)\n",
    "    print('train_t shape = ', train_t.shape, '\\n')\n",
    "    print('train_x shape = ', train_x.shape, '\\n')\n",
    "    \n",
    "    # if valid:\n",
    "        #if you want to also make a validation data set\n",
    "    train_data, valid_data = train_test_split(train_data, test_size=0.2)\n",
    "    valid_data = valid_data.reset_index(drop=True)\n",
    "    valid_t, valid_x = split_t_x(valid_data, target=target, source=source)\n",
    "\n",
    "        \n",
    "    return train_t, train_x, test_t,  test_x, valid_t, valid_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec59306f-2c48-4447-bd7d-67bd5f63dd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_t shape =  (800,) \n",
      "\n",
      "train_x shape =  (800, 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_t, train_x, test_t,  test_x, valid_t, valid_x = getwholedata_delta_C()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d79447d5-4b86-434a-bc15-22d5a7246317",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Features = train_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f90354bb-5400-4f88-8fb2-0bb66d42d10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_training_batch(x, t, batch_size):\n",
    "    # the numpy function choice(length, number)\n",
    "    # selects at random \"batch_size\" integers from \n",
    "    # the range [0, length-1] corresponding to the\n",
    "    # row indices.\n",
    "    rows    = np.random.choice(len(x), batch_size)\n",
    "    batch_x = x[rows]\n",
    "    batch_t = t[rows]\n",
    "    # batch_x.T[-1] = np.random.uniform(0, 1, batch_size)\n",
    "    return (batch_x, batch_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eab47ea9-5a2d-487e-838e-9c1fc50c5111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, PARAMS, pth_string):\n",
    "    \"\"\"pth string is the name of the pth file which is a \n",
    "    dictionary of dictionaries\"\"\"\n",
    "    models_path = os.path.join(os.getcwd(), '../models')\n",
    "    PATH=os.path.join(models_path, pth_string)\n",
    "    print(f'saving model with th string : {pth_string}\\n')\n",
    "    torch.save({'PARAMS': PARAMS,\n",
    "                'model_state_dict': model.state_dict()},\n",
    "                PATH)\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fa1ff7df-0a53-464d-9da9-9ad8f2676638",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS_Delta_C_nonMLE = {\n",
    "\"n_layers\": int(12),\n",
    "\"hidden_size\": int(12),\n",
    "\"dropout\": float(0.13),\n",
    "\"NFEATURES\":int(1),\n",
    "\"activation\": \"SiLU\",\n",
    "'optimizer_name':'NAdam',\n",
    "    # 'optimizer_name':'RMSprop',\n",
    "'starting_learning_rate':float(0.0006),\n",
    "'momentum':float(0.9),\n",
    "'batch_size':int(256*2),\n",
    "'n_iterations': int(4e3),\n",
    "'traces_step':int(100),\n",
    "'L2':float(0.1),\n",
    "'MLE':False,\n",
    "'with_lambda_D':True,\n",
    "'pth_string':'Delta_C_nonMLE_SILU.pth'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1339def5-72a4-4b5f-bce3-8343ab803949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_quadratic_loss(f, t, x):\n",
    "    # f and t must be of the same shape\n",
    "\n",
    "    # inv = torch.where(t !=0, 1/torch.abs(t), 1)\n",
    "    return  torch.mean((f - t)**2)\n",
    "\n",
    "def validate(model, avloss, inputs, targets):\n",
    "    # make sure we set evaluation mode so that any training specific\n",
    "    # operations are disabled.\n",
    "    model.eval() # evaluation mode\n",
    "    \n",
    "    with torch.no_grad(): # no need to compute gradients wrt. x and t\n",
    "        x = torch.from_numpy(inputs).float()\n",
    "        t = torch.from_numpy(targets).float()\n",
    "        # remember to reshape!\n",
    "        o = model(x).reshape(t.shape)\n",
    "    return avloss(o, t, x)\n",
    "def train(model, optimizer, avloss,\n",
    "          batch_size, \n",
    "          n_iterations, traces, \n",
    "          step, window, MLE, with_lambda_D):\n",
    "    \n",
    "    # to keep track of average losses\n",
    "    xx, yy_t, yy_v, yy_v_avg = traces\n",
    "    \n",
    "\n",
    "    \n",
    "    if MLE==True:\n",
    "        train_t, train_x, test_t,  test_x, _, _ = getwholedata_delta_C()\n",
    "    else:\n",
    "        train_t, train_x, test_t,  test_x, _, _ = getwholedata_delta_C()\n",
    "        \n",
    "    n = len(test_x)\n",
    "    print('Iteration vs average loss')\n",
    "    print(\"%10s\\t%10s\\t%10s\" % \\\n",
    "          ('iteration', 'train-set', 'valid-set'))\n",
    "    \n",
    "    # training_set_features, training_set_targets, evaluation_set_features, evaluation_set_targets = get_data_sets(simulate_data=False, batchsize=batch_size)\n",
    "    \n",
    "    for ii in range(n_iterations):\n",
    "\n",
    "        # set mode to training so that training specific \n",
    "        # operations such as dropout are enabled.\n",
    "\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        # get a random sample (a batch) of data (as numpy arrays)\n",
    "        \n",
    "        #Harrison-like Loader\n",
    "        batch_x, batch_t = get_features_training_batch(train_x, train_t, batch_size)\n",
    "        \n",
    "        #Or Ali's Loader\n",
    "        # batch_x, batch_t = next(training_set_features()), next(training_set_targets())\n",
    "        # batch_x_eval, batch_t_eval = next(evaluation_set_features()), next(evaluation_set_targets())\n",
    "\n",
    "        with torch.no_grad(): # no need to compute gradients \n",
    "            # wrt. x and t\n",
    "            x = torch.from_numpy(batch_x).float()\n",
    "            t = torch.from_numpy(batch_t).float()      \n",
    "\n",
    "\n",
    "        outputs = model(x).reshape(t.shape)\n",
    "   \n",
    "        # compute a noisy approximation to the average loss\n",
    "        empirical_risk = avloss(outputs, t, x)\n",
    "        \n",
    "        # use automatic differentiation to compute a \n",
    "        # noisy approximation of the local gradient\n",
    "        optimizer.zero_grad()       # clear previous gradients\n",
    "        empirical_risk.backward()   # compute gradients\n",
    "        \n",
    "        # finally, advance one step in the direction of steepest \n",
    "        # descent, using the noisy local gradient. \n",
    "        optimizer.step()            # move one step\n",
    "        \n",
    "        if ii % step == 0:\n",
    "            \n",
    "            \n",
    "            #using Harrison-like loader\n",
    "            acc_t = validate(model, avloss, train_x[:n], train_t[:n]) \n",
    "            acc_v = validate(model, avloss, test_x[:n], test_t[:n])\n",
    "            \n",
    "            #using Ali's loader\n",
    "            # acc_t = validate(model, avloss, batch_x, batch_t) \n",
    "            # acc_v = validate(model, avloss, batch_x_eval, batch_t_eval)\n",
    "            \n",
    "\n",
    "            yy_t.append(acc_t)\n",
    "            yy_v.append(acc_v)\n",
    "            \n",
    "            # compute running average for validation data\n",
    "            len_yy_v = len(yy_v)\n",
    "            if   len_yy_v < window:\n",
    "                yy_v_avg.append( yy_v[-1] )\n",
    "            elif len_yy_v == window:\n",
    "                yy_v_avg.append( sum(yy_v) / window )\n",
    "            else:\n",
    "                acc_v_avg  = yy_v_avg[-1] * window\n",
    "                acc_v_avg += yy_v[-1] - yy_v[-window-1]\n",
    "                yy_v_avg.append(acc_v_avg / window)\n",
    "                        \n",
    "            if len(xx) < 1:\n",
    "                xx.append(0)\n",
    "                print(\"%10d\\t%10.6f\\t%10.6f\" % \\\n",
    "                      (xx[-1], yy_t[-1], yy_v[-1]))\n",
    "            else:\n",
    "                xx.append(xx[-1] + step)\n",
    "                    \n",
    "                print(\"\\r%10d\\t%10.6f\\t%10.6f\\t%10.6f\" % \\\n",
    "                          (xx[-1], yy_t[-1], yy_v[-1], yy_v_avg[-1]), \n",
    "                      end='')\n",
    "            \n",
    "    print()      \n",
    "    return (xx, yy_t, yy_v, yy_v_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7198bb72-c019-45a0-b539-5bf9b9432696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling load_untrained_model({'n_layers': 12, 'hidden_size': 12, 'dropout': 0.13, 'NFEATURES': 1, 'activation': 'SiLU', 'optimizer_name': 'NAdam', 'starting_learning_rate': 0.0006, 'momentum': 0.9, 'batch_size': 512, 'n_iterations': 4000, 'traces_step': 100, 'L2': 0.1, 'MLE': False, 'with_lambda_D': True, 'pth_string': 'Delta_C_nonMLE_SILU.pth'})\n",
      "INITIATED UNTRAINED MODEL:\n",
      "'load_untrained_model' returned SiLURegressionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=12, bias=True)\n",
      "    (1): Dropout(p=0.13, inplace=False)\n",
      "    (2): SiLU()\n",
      "    (3): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (4): Dropout(p=0.13, inplace=False)\n",
      "    (5): SiLU()\n",
      "    (6): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (7): Dropout(p=0.13, inplace=False)\n",
      "    (8): SiLU()\n",
      "    (9): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (10): Dropout(p=0.13, inplace=False)\n",
      "    (11): SiLU()\n",
      "    (12): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (13): Dropout(p=0.13, inplace=False)\n",
      "    (14): SiLU()\n",
      "    (15): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (16): Dropout(p=0.13, inplace=False)\n",
      "    (17): SiLU()\n",
      "    (18): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (19): Dropout(p=0.13, inplace=False)\n",
      "    (20): SiLU()\n",
      "    (21): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (22): Dropout(p=0.13, inplace=False)\n",
      "    (23): SiLU()\n",
      "    (24): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (25): Dropout(p=0.13, inplace=False)\n",
      "    (26): SiLU()\n",
      "    (27): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (28): Dropout(p=0.13, inplace=False)\n",
      "    (29): SiLU()\n",
      "    (30): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (31): Dropout(p=0.13, inplace=False)\n",
      "    (32): SiLU()\n",
      "    (33): Linear(in_features=12, out_features=12, bias=True)\n",
      "    (34): Dropout(p=0.13, inplace=False)\n",
      "    (35): SiLU()\n",
      "    (36): Linear(in_features=12, out_features=1, bias=True)\n",
      "    (37): Sigmoid()\n",
      "  )\n",
      ")\n",
      "train_t shape =  (800,) \n",
      "\n",
      "train_x shape =  (800, 1) \n",
      "\n",
      "Iteration vs average loss\n",
      " iteration\t train-set\t valid-set\n",
      "         0\t  0.209617\t  0.208581\n",
      "      2000\t  0.001619\t  0.001616\t  0.001616\n"
     ]
    }
   ],
   "source": [
    "untrained_Delta_C_nonMLE = load_untrained_model(PARAMS_Delta_C_nonMLE)\n",
    "\n",
    "BATCHSIZE=PARAMS_Delta_C_nonMLE[\"batch_size\"]\n",
    "traces_SiLU = ([], [], [], [])\n",
    "traces_step = 2000\n",
    "optimizer_name=PARAMS_Delta_C_nonMLE[\"optimizer_name\"]\n",
    "\n",
    "optimizer_SiLU = getattr(torch.optim, str(optimizer_name))(untrained_Delta_C_nonMLE.parameters(), \n",
    "                                                           lr=PARAMS_Delta_C_nonMLE[\"starting_learning_rate\"])\n",
    "\n",
    "traces_SiLU = train(model=untrained_Delta_C_nonMLE, \n",
    "              optimizer=optimizer_SiLU, \n",
    "              avloss=average_quadratic_loss,\n",
    "              batch_size=BATCHSIZE, \n",
    "              n_iterations=PARAMS_Delta_C_nonMLE[\"n_iterations\"], \n",
    "              traces=traces_SiLU, \n",
    "              step=traces_step, \n",
    "              window=200,\n",
    "                MLE=False,\n",
    "                with_lambda_D=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4844159e-7547-48aa-aab0-3621f91c8693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "delta_C_hat = untrained_Delta_C_nonMLE(torch.Tensor(train_x)).detach().numpy().flatten()\n",
    "plt.scatter(train_x[:,-1].flatten(),delta_C_hat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ac7ed4-2efe-4329-b0de-7f94e2f09201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
